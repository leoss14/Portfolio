{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1183e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# RUNNING STAGE 2: ML GENDER PREDICTION\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "STAGE 2: ML GENDER PREDICTION PIPELINE\n",
      "======================================================================\n",
      "Main dataset: 21,436 products\n",
      "Human-coded: 259 products\n",
      "Your labeled: 44 products\n",
      "Filtered: 21,436 -> 12,832 (excluded 8,604)\n",
      "Label distribution: {'none': 10913, 'female': 1075, 'male': 844}\n",
      "Human labels merged: 200\n",
      "Color cache: 5,525 products\n",
      "  Matched to filtered data: 5,525 / 5,525\n",
      "\n",
      "Explicitly female: 1075, male: 844\n",
      "Balancing to: 844 per class\n",
      "Training data: 2532 (classes: {0: 850, 1: 845, 2: 837})\n",
      "Train: 1905, Test: 639\n",
      "Breadcrumb TF-IDF: 80 features\n",
      "Description TF-IDF: 150 features\n",
      "Color lookup built: 5,525 products\n",
      "  Color features filled for 822/1905 rows\n",
      "  Color features filled for 293/639 rows\n",
      "Color features: 93 (available for 822/1905 train samples)\n",
      "X_train: (1905, 329), X_test: (639, 329)\n",
      "\n",
      "--- Logistic Regression (L1) ---\n",
      "Accuracy: 0.6495, F1: 0.6462\n",
      "\n",
      "--- Logistic Regression (L2) ---\n",
      "Accuracy: 0.7277, F1: 0.7279\n",
      "\n",
      "--- Random Forest ---\n",
      "Accuracy: 0.7183, F1: 0.7168\n",
      "\n",
      "--- Histogram Gradient Boosting ---\n",
      "Accuracy: 0.8013, F1: 0.8009\n",
      "\n",
      "--- SVM (RBF) ---\n",
      "Accuracy: 0.7293, F1: 0.7276\n",
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON\n",
      "======================================================================\n",
      "                 Model  Accuracy  F1_weighted\n",
      "Hist Gradient Boosting  0.801252     0.800866\n",
      "            L2 (Ridge)  0.727700     0.727863\n",
      "                   SVM  0.729264     0.727643\n",
      "         Random Forest  0.718310     0.716787\n",
      "            L1 (LASSO)  0.649452     0.646213\n",
      "\n",
      "Best model: Hist Gradient Boosting\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.80      0.77      0.78       217\n",
      "        male       0.82      0.78      0.80       213\n",
      "        none       0.79      0.86      0.82       209\n",
      "\n",
      "    accuracy                           0.80       639\n",
      "   macro avg       0.80      0.80      0.80       639\n",
      "weighted avg       0.80      0.80      0.80       639\n",
      "\n",
      "Confusion Matrix:\n",
      "            Predicted\n",
      "            female  male  none\n",
      "Actual female   167    25    25\n",
      "Actual male      23   166    24\n",
      "Actual none      19    11   179\n",
      "\n",
      "Top 15 FEMALE features:\n",
      "  bc_removal                              : +1.0597\n",
      "  bc_period                               : +0.9417\n",
      "  bc_intimate                             : +0.8859\n",
      "  desc_protection                         : +0.7037\n",
      "  bc_products                             : +0.6726\n",
      "  bc_supplements                          : +0.4983\n",
      "  bc_shaving                              : +0.3979\n",
      "  desc_skin                               : +0.3952\n",
      "  bc_entertainment                        : +0.3707\n",
      "  bc_birthday                             : +0.3671\n",
      "  bc_sets                                 : +0.3585\n",
      "  desc_body                               : +0.3552\n",
      "  desc_vitamin                            : +0.3492\n",
      "  feat_color1_lavender                    : +0.3453\n",
      "  bc_pads                                 : +0.3312\n",
      "\n",
      "Top 15 MALE features:\n",
      "  bc_toiletries                           : +1.8629\n",
      "  desc_lynx                               : +1.0444\n",
      "  bc_gel                                  : +0.8752\n",
      "  bc_razors                               : +0.8255\n",
      "  bc_blades                               : +0.6738\n",
      "  bc_deodorants                           : +0.6308\n",
      "  bc_skincare                             : +0.6276\n",
      "  desc_shave                              : +0.5838\n",
      "  feat_color1_black                       : +0.5687\n",
      "  bc_body                                 : +0.4507\n",
      "  bc_deodorant                            : +0.4502\n",
      "  bc_wash                                 : +0.4373\n",
      "  desc_gel                                : +0.3922\n",
      "  bc_foam                                 : +0.3870\n",
      "  bc_aftershaves                          : +0.3417\n",
      "\n",
      "Top 15 NONE features:\n",
      "  bc_accessories                          : +0.7878\n",
      "  bc_conditioner                          : +0.6671\n",
      "  bc_dine                                 : +0.6505\n",
      "  bc_cook                                 : +0.6505\n",
      "  bc_marketplace                          : +0.6492\n",
      "  bc_toothpaste                           : +0.6098\n",
      "  bc_frozen                               : +0.6037\n",
      "  bc_care                                 : +0.5241\n",
      "  bc_baby                                 : +0.4803\n",
      "  bc_bath                                 : +0.4785\n",
      "  bc_sweets                               : +0.4005\n",
      "  bc_shampoo                              : +0.3899\n",
      "  bc_wellbeing                            : +0.3481\n",
      "  bc_toys                                 : +0.3359\n",
      "  bc_chocolate                            : +0.3350\n",
      "\n",
      "Prediction distribution:\n",
      "ml_pred_label\n",
      "none      9191\n",
      "female    2257\n",
      "male      1384\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Color impact:\n",
      "  WITH colors:    Accuracy=0.6495, F1=0.6462\n",
      "  WITHOUT colors: Accuracy=0.6275, F1=0.6223\n",
      "  Delta:          Accuracy +2.19pp, F1 +2.39pp\n",
      "\n",
      "Morrisons-only color ablation (HGB):  train=822, test=293\n",
      "  HGB WITH colors:    Accuracy=0.8396, F1=0.8399\n",
      "  HGB WITHOUT colors: Accuracy=0.8191, F1=0.8192\n",
      "  Delta (Morrisons HGB): Accuracy +2.05pp, F1 +2.08pp\n",
      "\n",
      "Products with human labels: 200\n",
      "Accuracy vs human: 0.7000\n",
      "\n",
      "Implicit female (>50% conf): 538\n",
      "Implicit male (>50% conf): 278\n",
      "\n",
      "Available for validation: 12,632\n",
      "  Sampled 85 female\n",
      "  Sampled 85 male\n",
      "  Sampled 85 none\n",
      "Saved validation sample: 255 products\n",
      "\n",
      "Pipeline complete. Charts in /Users/leoss/Desktop/Portfolio/Website-/projects/pink-tax/outputs/charts/ml, tables in /Users/leoss/Desktop/Portfolio/Website-/projects/pink-tax/outputs/text\n",
      "\n",
      "######################################################################\n",
      "# RUNNING STAGE 3: REGRESSION ANALYSIS\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "STAGE 3: REGRESSION ANALYSIS\n",
      "======================================================================\n",
      "Products with valid prices: 12,832\n",
      "\n",
      "Gender distribution:\n",
      "  female: 1,075  (mean 7.03, median 4.00)\n",
      "  male: 844  (mean 8.15, median 4.50)\n",
      "  none: 10,913  (mean 10.66, median 5.00)\n",
      "\n",
      "Gendered sample: N = 1,919 (F: 1075, M: 844)\n",
      "\n",
      "Spec 1: Raw gap\n",
      "  (1) Raw gap: coef=-0.0975 (-9.3%), SE=0.0411, p=0.0178**, R2=0.003, N=1919\n",
      "\n",
      "Spec 2: + Store FE\n",
      "  (2) + Store FE: coef=-0.1036 (-9.8%), SE=0.0412, p=0.0118**, R2=0.006, N=1919\n",
      "\n",
      "Spec 3: + Broad cat FE (N cats: 96)\n",
      "  (3) + Broad cat FE: coef=+0.0803 (+8.4%), SE=0.0851, p=0.3454, R2=0.672, N=1374\n",
      "\n",
      "Spec 4: + Mid cat FE (N cats: 96)\n",
      "  (4) + Mid cat FE: coef=+0.0803 (+8.4%), SE=0.0851, p=0.3454, R2=0.672, N=1374\n",
      "\n",
      "Spec 5: + Fine cat FE (N cats: 96)\n",
      "  (5) + Fine cat FE: coef=+0.0803 (+8.4%), SE=0.0851, p=0.3454, R2=0.672, N=1374\n",
      "\n",
      "Spec 6: + Description TF-IDF\n",
      "  (6) + Description: coef=+0.0367 (+3.7%), SE=0.0675, p=0.5868, R2=0.738\n",
      "\n",
      "Spec 7: Female x Store interaction\n",
      "  Main effect (is_female): -0.0412 (p=0.5918)\n",
      "  Store 3: total female effect = -0.7046 (-50.6%), interaction p=0.0000\n",
      "  Store 4: total female effect = +0.2767 (+31.9%), interaction p=0.0969\n",
      "\n",
      "Spec 8: Unit price regression\n",
      "  (8) Unit price: coef=+0.0067 (+0.7%), SE=0.0677, p=0.9218, R2=0.854, N=743\n",
      "\n",
      "Spec 9: Three-way comparison (none = reference)\n",
      "  is_female: -0.1794 (p=0.0000)\n",
      "  is_male:   -0.0299 (p=0.3745)\n",
      "\n",
      "======================================================================\n",
      "QUANTILE REGRESSION\n",
      "======================================================================\n",
      "  Q0.10: coef=-0.1285 (-12.1%), p=0.0440**\n",
      "  Q0.25: coef=-0.0000 (-0.0%), p=0.9999\n",
      "  Q0.50: coef=-0.1054 (-10.0%), p=0.0217**\n",
      "  Q0.75: coef=+0.0000 (+0.0%), p=1.0000\n",
      "  Q0.90: coef=-0.2226 (-20.0%), p=0.0023***\n",
      "\n",
      "  With mid-category controls:\n",
      "  Q0.10: coef=+0.3578 (+43.0%), p=0.0000***\n",
      "  Q0.25: coef=+0.2231 (+25.0%), p=0.0002***\n",
      "  Q0.50: coef=+0.0000 (+0.0%), p=1.0000\n",
      "  Q0.75: coef=+0.0000 (+0.0%), p=1.0000\n",
      "  Q0.90: coef=+0.0000 (+0.0%), p=1.0000\n",
      "\n",
      "======================================================================\n",
      "WITHIN-CATEGORY ANALYSIS (bootstrap CIs)\n",
      "======================================================================\n",
      "Categories with both genders (>=3 each): 11\n",
      "  Weighted mean: +26.2%\n",
      "  Median: +7.4%\n",
      "\n",
      "======================================================================\n",
      "PINK TAX BY STORE\n",
      "======================================================================\n",
      "  Store 4         F: 449 M: 404 gap=   +0.8% p=0.8938\n",
      "  Store 3         F:  29 M:  34 gap=   -5.1% p=0.8036\n",
      "  Store 1         F: 597 M: 406 gap=  -18.6% p=0.0003***\n",
      "\n",
      "======================================================================\n",
      "REGRESSION SUMMARY\n",
      "======================================================================\n",
      "Spec                          Coef     %gap             95% CI        p     R2      N\n",
      "(1) Raw gap               -0.0975    -9.3% [ -16.3,   -1.7]  0.0178**  0.003   1919\n",
      "(2) + Store FE            -0.1036    -9.8% [ -16.8,   -2.3]  0.0118**  0.006   1919\n",
      "(3) + Broad cat FE        +0.0803    +8.4% [  -8.3,  +28.0]  0.3454    0.672   1374\n",
      "(4) + Mid cat FE          +0.0803    +8.4% [  -8.3,  +28.0]  0.3454    0.672   1374\n",
      "(5) + Fine cat FE         +0.0803    +8.4% [  -8.3,  +28.0]  0.3454    0.672   1374\n",
      "(6) + Description         +0.0367    +3.7% [  -9.1,  +18.4]  0.5868    0.738   1374\n",
      "(8) Unit price            +0.0067    +0.7% [ -11.8,  +15.0]  0.9218    0.854    743\n",
      "\n",
      "======================================================================\n",
      "GENERATING CHARTS (Plotly)\n",
      "======================================================================\n",
      "   ✓ 01_coefficient_plot.html\n",
      "   ✓ 02_quantile_regression.html\n",
      "   ✓ 03_within_category_gaps.html\n",
      "   ✓ 04_price_distributions.html\n",
      "   ✓ 05_by_store.html\n",
      "   ✓ 06_scatter_by_category.html\n",
      "   ✓ 07_three_way_comparison.html\n",
      "   ✓ 08_category_composition.html\n",
      "   ✓ 09_gap_distribution.html\n",
      "   ✓ 10_r2_progression.html\n",
      "   ✓ 12_summary_dashboard.html\n",
      "   ✓ 13_waterfall_decomposition.html\n",
      "\n",
      "Charts saved to /Users/leoss/Desktop/Portfolio/Website-/projects/pink-tax/outputs/charts/regression, tables in /Users/leoss/Desktop/Portfolio/Website-/projects/pink-tax/outputs/text\n",
      "\n",
      "######################################################################\n",
      "# RUNNING STAGE 4: COLOR VISUALISATIONS\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "STAGE 4: COLOR VISUALISATIONS (Plotly)\n",
      "======================================================================\n",
      "Color cache: 5,525 products\n",
      "Feature importance: 329 features\n",
      "Colors with >1% share: 21\n",
      "\n",
      "Generating color distribution chart...\n",
      "   ✓ color_distribution_by_gender.html\n",
      "\n",
      "Generating color importance chart...\n",
      "   ✓ color_importance.html\n",
      "\n",
      "Generating color importance heatmap...\n",
      "   ✓ color_importance_heatmap.html\n",
      "\n",
      "Generating female vs male color comparison...\n",
      "   ✓ color_comparison_butterfly.html\n",
      "\n",
      "All charts saved to /Users/leoss/Desktop/Portfolio/Website-/projects/pink-tax/outputs/charts/validation\n",
      "Usage: run_pipeline(stages) where stages = 1, 2, 3, 4, or 'all'\n",
      "  e.g. run_pipeline(2)  or  run_pipeline([2, 3])  or  run_pipeline('all')\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PINK TAX ANALYSIS - UNIFIED PIPELINE\n",
    "# ============================================================================\n",
    "#\n",
    "# Consolidates four previously separate scripts into one modular codebase:\n",
    "#   Stage 1: Color extraction from product images (adaptive domain handling)\n",
    "#   Stage 2: ML-based gender prediction (L1/L2/RF/HGB/SVM)\n",
    "#   Stage 3: Regression analysis (OLS, quantile, within-category, by-store)\n",
    "#   Stage 4: Color visualisations for portfolio\n",
    "#\n",
    "# Usage:\n",
    "#   python pink_tax_pipeline.py --stage [1|2|3|4|all]\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "BASE_DIR = Path('/Users/leoss/Desktop/Portfolio/Website-/projects')\n",
    "DATA_DIR = BASE_DIR / 'pink-tax/data'\n",
    "OUTPUT_BASE = BASE_DIR / 'pink-tax/outputs'\n",
    "\n",
    "# Input files\n",
    "PATH_MAIN_DATA = DATA_DIR / 'items_fin.csv'\n",
    "PATH_HUMAN_CODED = DATA_DIR / 'items_prices_description_gender_humancode_sample.csv'\n",
    "PATH_YOUR_LABELED = DATA_DIR / 'available_validation.xlsx'\n",
    "\n",
    "# Output directories\n",
    "# Colour scraping outputs\n",
    "COLOUR_DIR = OUTPUT_BASE / 'colour'\n",
    "COLOR_CACHE_PATH = COLOUR_DIR / 'color_features_cache_v3_filtered.csv'\n",
    "FAILED_URLS_PATH = COLOUR_DIR / 'failed_urls.csv'\n",
    "\n",
    "# Chart outputs (interactive HTML)\n",
    "CHART_REG_DIR = OUTPUT_BASE / 'charts/regression'\n",
    "CHART_ML_DIR = OUTPUT_BASE / 'charts/ml'\n",
    "CHART_VAL_DIR = OUTPUT_BASE / 'charts/validation'\n",
    "\n",
    "# Tabular and summary outputs\n",
    "TEXT_DIR = OUTPUT_BASE / 'text'\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ---- Column names ----\n",
    "COL_PRODUCT_ID = 'product_id'\n",
    "COL_IMAGE = 'image_url'\n",
    "COL_BREADCRUMB = 'standardized_breadcrumbs'\n",
    "COL_NAME = 'product_title_x'\n",
    "COL_DESC = 'description'\n",
    "COL_PRICE = 'price'\n",
    "COL_UNIT_PRICE = 'unit_price'\n",
    "COL_STORE = 'store_id'\n",
    "COL_URL = 'product_url_x'\n",
    "\n",
    "# ---- Gender keywords ----\n",
    "FEMALE_KEYWORDS = [\n",
    "    'women', 'woman', 'female', 'ladies', 'lady', 'girls',\n",
    "    'womens', \"women's\", 'femme', 'her', 'feminine', 'fem',\n",
    "]\n",
    "MALE_KEYWORDS = [\n",
    "    'men', 'man', 'male', 'gentleman', 'gentlemen', 'boys',\n",
    "    'mens', \"men's\", 'homme', 'his', 'masculine',\n",
    "]\n",
    "ALL_GENDER_KEYWORDS = set(FEMALE_KEYWORDS + MALE_KEYWORDS)\n",
    "\n",
    "# ---- Category exclusions ----\n",
    "EXCLUDE_CATEGORIES = [\n",
    "    'food', 'grocery', 'groceries', 'snacks', 'drinks', 'beverages',\n",
    "    'pet food', 'pet supplies', 'cleaning', 'household', 'kitchen',\n",
    "    'office', 'stationery', 'electronics', 'tech', 'garden', 'automotive',\n",
    "]\n",
    "\n",
    "# ---- Color definitions ----\n",
    "STANDARD_COLORS = {\n",
    "    'dark_red': (139, 0, 0), 'red': (255, 0, 0), 'coral': (255, 127, 80),\n",
    "    'salmon': (250, 128, 114), 'crimson': (220, 20, 60), 'brown': (139, 69, 19),\n",
    "    'tan': (210, 180, 140), 'orange': (255, 165, 0), 'gold': (255, 215, 0),\n",
    "    'yellow': (255, 255, 0), 'khaki': (240, 230, 140), 'dark_green': (0, 100, 0),\n",
    "    'green': (0, 128, 0), 'lime': (50, 205, 50), 'olive': (128, 128, 0),\n",
    "    'teal': (0, 128, 128), 'navy': (0, 0, 128), 'blue': (0, 0, 255),\n",
    "    'royal_blue': (65, 105, 225), 'sky_blue': (135, 206, 235), 'cyan': (0, 255, 255),\n",
    "    'purple': (128, 0, 128), 'magenta': (255, 0, 255), 'violet': (238, 130, 238),\n",
    "    'lavender': (230, 230, 250), 'pink': (255, 192, 203), 'hot_pink': (255, 105, 180),\n",
    "    'gray': (128, 128, 128), 'silver': (192, 192, 192),\n",
    "    'black': (0, 0, 0), 'white': (255, 255, 255),\n",
    "}\n",
    "\n",
    "# ---- Stage 1 settings ----\n",
    "N_COLORS = 3\n",
    "TIMEOUT = 15\n",
    "MAX_SAMPLES = 20000\n",
    "PRIORITIZE_GENDERED = False\n",
    "MAX_RETRIES = 1\n",
    "RETRY_DELAY = 1\n",
    "SAVE_EVERY = 200\n",
    "MIN_DOMAIN_SAMPLES = 30\n",
    "HEAD_CHECK_THRESHOLD = 0.40\n",
    "SKIP_THRESHOLD = 0.05\n",
    "\n",
    "# ---- Stage 2 settings ----\n",
    "TEST_SIZE = 0.25\n",
    "CV_FOLDS = 5\n",
    "MIN_CLASS_SIZE = 50\n",
    "MIN_TEST_SAMPLES = 10\n",
    "\n",
    "# ---- Stage 3 settings ----\n",
    "N_BOOTSTRAP = 1000\n",
    "\n",
    "# ---- Chart style ----\n",
    "PALETTE = {'female': '#c44e52', 'male': '#4c72b0', 'none': '#8c8c8c'}\n",
    "\n",
    "# ---- Unified portfolio style (Plotly) ----\n",
    "STYLE = {\n",
    "    'font_family': 'IBM Plex Sans, -apple-system, BlinkMacSystemFont, sans-serif',\n",
    "    'tick_size': 11,\n",
    "    'axis_title_size': 13,\n",
    "    'legend_size': 11,\n",
    "    'annotation_size': 10,\n",
    "    'title_color': '#1a2744',\n",
    "    'navy': '#1a2744',\n",
    "    'slate': '#3d4f5f',\n",
    "    'steel': '#4a6fa5',\n",
    "    'grey_300': '#c9cfd6',\n",
    "    'grey_200': '#dde1e7',\n",
    "    'grey_100': '#f0f2f5',\n",
    "    'text_secondary': '#5a6675',\n",
    "    'pos_color': '#2e7d4a',\n",
    "    'neg_color': '#c23a3a',\n",
    "    'zero_line_color': '#c9cfd6',\n",
    "    'template': 'plotly_white',\n",
    "    'plot_bg': 'rgba(0,0,0,0)',\n",
    "    'paper_bg': 'white',\n",
    "    'chart_height': 550,\n",
    "    'chart_height_small': 420,\n",
    "    'chart_height_tall': 700,\n",
    "    'margin_default': dict(l=60, r=40, t=20, b=50),\n",
    "    'margin_bar': dict(l=200, r=60, t=20, b=50),\n",
    "    'margin_map': dict(l=10, r=10, t=10, b=60),\n",
    "    'grid_color': '#e5e7eb',\n",
    "    'grid_width': 0.5,\n",
    "    'choropleth_line_color': '#c9cfd6',\n",
    "    'choropleth_line_width': 0.5,\n",
    "    'colorbar': dict(len=0.7, thickness=15),\n",
    "    'marker_line': dict(width=0.5, color='white'),\n",
    "}\n",
    "\n",
    "WRITE_CONFIG = {'displayModeBar': False}\n",
    "\n",
    "\n",
    "def base_layout(**overrides):\n",
    "    layout = dict(\n",
    "        template=STYLE['template'],\n",
    "        font=dict(family=STYLE['font_family'], size=STYLE['tick_size'],\n",
    "                  color='#4b5563'),\n",
    "        paper_bgcolor=STYLE['paper_bg'],\n",
    "        plot_bgcolor=STYLE['plot_bg'],\n",
    "        height=STYLE['chart_height'],\n",
    "        margin=STYLE['margin_default'],\n",
    "        title='',\n",
    "        hoverlabel=dict(\n",
    "            bgcolor='white',\n",
    "            bordercolor='#c9cfd6',\n",
    "            font=dict(family=STYLE['font_family'], size=13, color='#1a2744'),\n",
    "        ),\n",
    "    )\n",
    "    for k, v in overrides.items():\n",
    "        layout[k] = v\n",
    "    return layout\n",
    "\n",
    "\n",
    "def styled_axis(title_text, **kw):\n",
    "    d = dict(\n",
    "        title=dict(text=title_text,\n",
    "                   font=dict(size=STYLE['axis_title_size'],\n",
    "                             family=STYLE['font_family'])),\n",
    "        tickfont=dict(size=STYLE['tick_size'],\n",
    "                      family=STYLE['font_family']),\n",
    "        gridcolor=STYLE['grid_color'],\n",
    "        gridwidth=STYLE['grid_width'],\n",
    "        zeroline=False,\n",
    "    )\n",
    "    d.update(kw)\n",
    "    return d\n",
    "\n",
    "\n",
    "def save_html(fig, filepath):\n",
    "    fig.write_html(\n",
    "        str(filepath),\n",
    "        config=WRITE_CONFIG,\n",
    "        include_plotlyjs='cdn',\n",
    "    )\n",
    "    import os\n",
    "    print(f\"   \\u2713 {os.path.basename(str(filepath))}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SHARED UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def load_main_data(path=PATH_MAIN_DATA):\n",
    "    \"\"\"Load and normalise the main product dataset.\"\"\"\n",
    "    df = pd.read_csv(path, encoding='latin-1')\n",
    "    df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')\n",
    "    if 'unnamed:_0' in df.columns:\n",
    "        df = df.drop(columns=['unnamed:_0'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def contains_excluded_category(text):\n",
    "    \"\"\"Check whether a breadcrumb string matches any excluded category.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    text_lower = str(text).lower()\n",
    "    return any(cat in text_lower for cat in EXCLUDE_CATEGORIES)\n",
    "\n",
    "\n",
    "def filter_excluded_categories(df):\n",
    "    \"\"\"Remove products in excluded categories. Returns filtered copy.\"\"\"\n",
    "    mask = df[COL_BREADCRUMB].apply(contains_excluded_category)\n",
    "    return df[~mask].copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "def extract_gender_from_text(text):\n",
    "    \"\"\"Return 'female', 'male', 'both', or 'none' from a single text field.\"\"\"\n",
    "    if pd.isna(text) or str(text).strip() == '':\n",
    "        return 'none'\n",
    "    text_lower = str(text).lower()\n",
    "    has_female = any(re.search(r'\\b' + kw + r'\\b', text_lower) for kw in FEMALE_KEYWORDS)\n",
    "    has_male = any(re.search(r'\\b' + kw + r'\\b', text_lower) for kw in MALE_KEYWORDS)\n",
    "    if has_female and not has_male:\n",
    "        return 'female'\n",
    "    if has_male and not has_female:\n",
    "        return 'male'\n",
    "    if has_female and has_male:\n",
    "        return 'both'\n",
    "    return 'none'\n",
    "\n",
    "\n",
    "def extract_gender_label(row):\n",
    "    \"\"\"Combine gender signals from breadcrumb, title, and description.\"\"\"\n",
    "    for col in [COL_BREADCRUMB, COL_NAME, COL_DESC]:\n",
    "        if col in row.index:\n",
    "            gender = extract_gender_from_text(row[col])\n",
    "            if gender in ('female', 'male'):\n",
    "                return gender\n",
    "    return 'none'\n",
    "\n",
    "\n",
    "def add_gender_labels(df):\n",
    "    \"\"\"Add per-field and combined gender labels to the dataframe in place.\"\"\"\n",
    "    df['label_bc'] = df[COL_BREADCRUMB].apply(extract_gender_from_text)\n",
    "    df['label_name'] = df[COL_NAME].apply(extract_gender_from_text)\n",
    "    df['label_desc'] = df[COL_DESC].apply(extract_gender_from_text)\n",
    "    df['label_extracted'] = df.apply(extract_gender_label, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_text_remove_gender(text, remove_words=ALL_GENDER_KEYWORDS):\n",
    "    \"\"\"Lowercase, strip gender keywords and punctuation.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = str(text).lower()\n",
    "    for word in remove_words:\n",
    "        text = re.sub(r'\\b' + word + r'\\b', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_domain(url):\n",
    "    try:\n",
    "        return str(url).split('/')[2]\n",
    "    except (IndexError, AttributeError):\n",
    "        return 'unknown'\n",
    "\n",
    "\n",
    "def parse_breadcrumb(text):\n",
    "    \"\"\"Extract clean category levels from a breadcrumb string.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return 'unknown', 'unknown', 'unknown'\n",
    "    text = str(text).strip()\n",
    "    if ' > ' in text:\n",
    "        parts = [p.strip().lower() for p in text.split(' > ') if p.strip()]\n",
    "    elif ' / ' in text:\n",
    "        parts = [p.strip().lower() for p in text.split(' / ') if p.strip()]\n",
    "    else:\n",
    "        parts = [text.strip().lower()]\n",
    "\n",
    "    known_stores = {'morrisons', 'tesco', 'asda', 'groceries', 'marketplace'}\n",
    "    while parts and parts[0] in known_stores:\n",
    "        parts = parts[1:]\n",
    "\n",
    "    level1 = parts[0] if len(parts) > 0 else 'unknown'\n",
    "    level2 = parts[1] if len(parts) > 1 else 'unknown'\n",
    "    level3 = parts[2] if len(parts) > 2 else 'unknown'\n",
    "    return level1, level2, level3\n",
    "\n",
    "\n",
    "# ---- Color helpers ----\n",
    "\n",
    "def color_distance(c1, c2):\n",
    "    return np.sqrt(sum((a - b) ** 2 for a, b in zip(c1, c2)))\n",
    "\n",
    "\n",
    "def closest_standard_color(rgb):\n",
    "    min_dist = float('inf')\n",
    "    closest = 'gray'\n",
    "    for name, std_rgb in STANDARD_COLORS.items():\n",
    "        dist = color_distance(rgb, std_rgb)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest = name\n",
    "    return closest\n",
    "\n",
    "\n",
    "def is_background_color(rgb):\n",
    "    r, g, b = rgb\n",
    "    if r > 240 and g > 240 and b > 240:\n",
    "        return True\n",
    "    if r < 15 and g < 15 and b < 15:\n",
    "        return True\n",
    "    max_diff = max(abs(r - g), abs(g - b), abs(r - b))\n",
    "    avg = (r + g + b) / 3\n",
    "    if max_diff < 20 and 100 < avg < 160:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def rgb_norm(name):\n",
    "    \"\"\"Normalised RGB tuple (kept for compatibility).\"\"\"\n",
    "    r, g, b = STANDARD_COLORS.get(name, (128, 128, 128))\n",
    "    return (r / 255, g / 255, b / 255)\n",
    "\n",
    "\n",
    "def rgb_hex(name):\n",
    "    \"\"\"Hex color string for Plotly.\"\"\"\n",
    "    r, g, b = STANDARD_COLORS.get(name, (128, 128, 128))\n",
    "    return f'#{r:02x}{g:02x}{b:02x}'\n",
    "\n",
    "\n",
    "def text_color_for_bg(name):\n",
    "    \"\"\"Black or white text depending on background luminance.\"\"\"\n",
    "    r, g, b = STANDARD_COLORS.get(name, (128, 128, 128))\n",
    "    lum = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "    return 'white' if lum < 140 else '#1a1a1a'\n",
    "\n",
    "\n",
    "def edge_color_for(name):\n",
    "    \"\"\"Light colors get a visible border.\"\"\"\n",
    "    r, g, b = STANDARD_COLORS.get(name, (128, 128, 128))\n",
    "    lum = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "    return '#aaaaaa' if lum > 200 else 'none'\n",
    "\n",
    "\n",
    "def save_incremental(new_results, cache_path):\n",
    "    \"\"\"Append new results to the cache CSV, deduplicating on product_id.\"\"\"\n",
    "    if not new_results:\n",
    "        return 0\n",
    "    new_df = pd.DataFrame(new_results)\n",
    "    if cache_path.exists():\n",
    "        existing = pd.read_csv(cache_path)\n",
    "        combined = pd.concat([existing, new_df]).drop_duplicates(subset=[COL_PRODUCT_ID])\n",
    "    else:\n",
    "        combined = new_df\n",
    "    combined.to_csv(cache_path, index=False)\n",
    "    return len(combined)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STAGE 1: COLOR EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "class DomainTracker:\n",
    "    \"\"\"\n",
    "    Tracks per-domain success/failure rates during extraction.\n",
    "    After MIN_DOMAIN_SAMPLES attempts, adjusts strategy:\n",
    "      - success rate < HEAD_CHECK_THRESHOLD: HEAD pre-check before GET\n",
    "      - success rate < SKIP_THRESHOLD: skip entirely\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_samples, head_threshold, skip_threshold):\n",
    "        self.min_samples = min_samples\n",
    "        self.head_threshold = head_threshold\n",
    "        self.skip_threshold = skip_threshold\n",
    "        self.attempts = Counter()\n",
    "        self.successes = Counter()\n",
    "        self._notified_head = set()\n",
    "        self._notified_skip = set()\n",
    "\n",
    "    def record(self, domain, success):\n",
    "        self.attempts[domain] += 1\n",
    "        if success:\n",
    "            self.successes[domain] += 1\n",
    "\n",
    "    def success_rate(self, domain):\n",
    "        total = self.attempts[domain]\n",
    "        return self.successes[domain] / total if total else 1.0\n",
    "\n",
    "    def should_skip(self, domain):\n",
    "        if self.attempts[domain] < self.min_samples:\n",
    "            return False\n",
    "        skip = self.success_rate(domain) < self.skip_threshold\n",
    "        if skip and domain not in self._notified_skip:\n",
    "            rate = self.success_rate(domain)\n",
    "            print(f\"  [domain tracker] Skipping {domain} \"\n",
    "                  f\"(success rate {rate:.0%} after {self.attempts[domain]} attempts)\")\n",
    "            self._notified_skip.add(domain)\n",
    "        return skip\n",
    "\n",
    "    def should_head_check(self, domain):\n",
    "        if self.attempts[domain] < self.min_samples:\n",
    "            return False\n",
    "        rate = self.success_rate(domain)\n",
    "        head_check = rate < self.head_threshold and rate >= self.skip_threshold\n",
    "        if head_check and domain not in self._notified_head:\n",
    "            print(f\"  [domain tracker] HEAD pre-checking {domain} \"\n",
    "                  f\"(success rate {rate:.0%} after {self.attempts[domain]} attempts)\")\n",
    "            self._notified_head.add(domain)\n",
    "        return head_check\n",
    "\n",
    "    def summary(self):\n",
    "        out = {}\n",
    "        for domain in sorted(self.attempts, key=lambda d: self.attempts[d], reverse=True):\n",
    "            total = self.attempts[domain]\n",
    "            ok = self.successes[domain]\n",
    "            out[domain] = (ok, total, ok / total if total else 0)\n",
    "        return out\n",
    "\n",
    "\n",
    "def _build_session():\n",
    "    import requests\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        'User-Agent': (\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '\n",
    "            'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "            'Chrome/91.0.4472.124 Safari/537.36'\n",
    "        ),\n",
    "        'Accept': 'image/avif,image/webp,image/apng,image/*,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "    })\n",
    "    return session\n",
    "\n",
    "\n",
    "def _head_check_alive(session, url, timeout=5):\n",
    "    import requests\n",
    "    try:\n",
    "        resp = session.head(url, timeout=timeout, allow_redirects=True)\n",
    "        return resp.status_code == 200\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "\n",
    "\n",
    "def _is_transient_error(status_code):\n",
    "    if status_code is None:\n",
    "        return True\n",
    "    return status_code >= 500 or status_code == 429\n",
    "\n",
    "\n",
    "def extract_colors_from_url(session, domain_tracker, image_url,\n",
    "                            n_colors=3, timeout=15, max_retries=1):\n",
    "    \"\"\"\n",
    "    Download an image and extract dominant colors via KMeans.\n",
    "    Returns (colors_list | None, error_reason | None).\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    url = str(image_url).strip()\n",
    "    domain = get_domain(url)\n",
    "\n",
    "    if domain_tracker.should_skip(domain):\n",
    "        return None, 'adaptive_skip'\n",
    "    if domain_tracker.should_head_check(domain):\n",
    "        if not _head_check_alive(session, url, timeout=5):\n",
    "            return None, 'head_check_dead'\n",
    "\n",
    "    last_error = None\n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            response = session.get(url, timeout=timeout, allow_redirects=True)\n",
    "            if response.status_code != 200:\n",
    "                last_error = f'http_{response.status_code}'\n",
    "                if _is_transient_error(response.status_code) and attempt < max_retries:\n",
    "                    time.sleep(RETRY_DELAY)\n",
    "                    continue\n",
    "                return None, last_error\n",
    "\n",
    "            img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "            img = img.resize((100, 100))\n",
    "            pixels = np.array(img).reshape(-1, 3)\n",
    "\n",
    "            non_bg = np.array([p for p in pixels if not is_background_color(tuple(p))])\n",
    "            if len(non_bg) < 50:\n",
    "                non_bg = pixels\n",
    "\n",
    "            n_clusters = min(n_colors + 2, len(non_bg))\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "            kmeans.fit(non_bg)\n",
    "\n",
    "            counts = Counter(kmeans.labels_)\n",
    "            total = len(kmeans.labels_)\n",
    "            colors = []\n",
    "            for cluster_id, count in sorted(counts.items(), key=lambda x: x[1], reverse=True):\n",
    "                rgb = tuple(int(c) for c in kmeans.cluster_centers_[cluster_id])\n",
    "                if not is_background_color(rgb):\n",
    "                    colors.append({'name': closest_standard_color(rgb), 'weight': count / total})\n",
    "                if len(colors) >= n_colors:\n",
    "                    break\n",
    "\n",
    "            return (colors, None) if colors else (None, 'no_non_bg_colors')\n",
    "\n",
    "        except requests.exceptions.Timeout:\n",
    "            last_error = 'timeout'\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            last_error = 'connection_error'\n",
    "        except requests.exceptions.RequestException:\n",
    "            last_error = 'request_error'\n",
    "        except Exception:\n",
    "            last_error = 'processing_error'\n",
    "\n",
    "        if attempt < max_retries:\n",
    "            time.sleep(RETRY_DELAY)\n",
    "\n",
    "    return None, last_error\n",
    "\n",
    "\n",
    "def run_color_extraction():\n",
    "    \"\"\"Stage 1: extract dominant colors from product images.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"STAGE 1: COLOR EXTRACTION (adaptive domain handling)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Timeout: {TIMEOUT}s | Retries: {MAX_RETRIES} (transient only)\")\n",
    "    print(f\"Adaptive thresholds: HEAD-check < {HEAD_CHECK_THRESHOLD:.0%} \"\n",
    "          f\"success, skip < {SKIP_THRESHOLD:.0%} success \"\n",
    "          f\"(after {MIN_DOMAIN_SAMPLES} samples)\")\n",
    "    print()\n",
    "\n",
    "    OUTPUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "    COLOUR_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    session = _build_session()\n",
    "    domain_tracker = DomainTracker(MIN_DOMAIN_SAMPLES, HEAD_CHECK_THRESHOLD, SKIP_THRESHOLD)\n",
    "\n",
    "    # Resume support\n",
    "    already_done = set()\n",
    "    if COLOR_CACHE_PATH.exists():\n",
    "        existing = pd.read_csv(COLOR_CACHE_PATH)\n",
    "        if COL_PRODUCT_ID in existing.columns:\n",
    "            already_done = set(existing[COL_PRODUCT_ID].astype(str))\n",
    "            print(f\"Existing cache: {len(already_done):,} products -- will resume.\\n\")\n",
    "\n",
    "    # Load and filter\n",
    "    print(\"Loading data...\")\n",
    "    df = load_main_data()\n",
    "    print(f\"  Loaded {len(df):,} products\")\n",
    "\n",
    "    print(\"Filtering categories...\")\n",
    "    df = filter_excluded_categories(df)\n",
    "    print(f\"  Remaining: {len(df):,} products\")\n",
    "\n",
    "    print(\"Extracting gender labels...\")\n",
    "    df = add_gender_labels(df)\n",
    "    for label, count in df['label_extracted'].value_counts().items():\n",
    "        print(f\"  {label}: {count:,}\")\n",
    "\n",
    "    print(\"Selecting products...\")\n",
    "    df_with_images = df[df[COL_IMAGE].notna()].copy()\n",
    "\n",
    "    df_with_images['_domain'] = df_with_images[COL_IMAGE].apply(get_domain)\n",
    "    print(\"  Domain breakdown:\")\n",
    "    for domain, count in df_with_images['_domain'].value_counts().items():\n",
    "        print(f\"    {domain}: {count:,}\")\n",
    "\n",
    "    to_extract = df_with_images.copy()\n",
    "    if len(to_extract) > MAX_SAMPLES:\n",
    "        to_extract = to_extract.sample(n=MAX_SAMPLES, random_state=RANDOM_STATE)\n",
    "\n",
    "    to_extract = to_extract[~to_extract[COL_PRODUCT_ID].astype(str).isin(already_done)]\n",
    "    print(f\"  To process (after resume filter): {len(to_extract):,}\")\n",
    "\n",
    "    # Extract\n",
    "    print(f\"\\nExtracting colors (top {N_COLORS} per image)...\\n\")\n",
    "\n",
    "    color_results = []\n",
    "    failed_records = []\n",
    "    error_counter = Counter()\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (row_idx, row) in enumerate(to_extract.iterrows()):\n",
    "        if (idx + 1) % 100 == 0 or idx == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            rate = (idx + 1) / elapsed if elapsed > 0 else 0\n",
    "            remaining = (len(to_extract) - idx - 1) / rate if rate > 0 else 0\n",
    "            ok = len(color_results)\n",
    "            total_so_far = idx + 1\n",
    "            pct = 100 * ok / total_so_far if total_so_far else 0\n",
    "            print(f\"  {idx+1:,}/{len(to_extract):,} \"\n",
    "                  f\"| OK: {ok} ({pct:.0f}%) \"\n",
    "                  f\"| {rate:.1f} img/s \"\n",
    "                  f\"| ETA: {remaining/60:.0f} min\")\n",
    "\n",
    "        url = row[COL_IMAGE]\n",
    "        domain = get_domain(str(url))\n",
    "\n",
    "        colors, error = extract_colors_from_url(\n",
    "            session, domain_tracker, url,\n",
    "            n_colors=N_COLORS, timeout=TIMEOUT, max_retries=MAX_RETRIES,\n",
    "        )\n",
    "\n",
    "        success = colors is not None\n",
    "        domain_tracker.record(domain, success)\n",
    "\n",
    "        if success:\n",
    "            entry = {\n",
    "                'original_index': row_idx,\n",
    "                COL_PRODUCT_ID: row[COL_PRODUCT_ID],\n",
    "                'label_extracted': row['label_extracted'],\n",
    "            }\n",
    "            for i, c in enumerate(colors):\n",
    "                entry[f'color{i+1}_name'] = c['name']\n",
    "                entry[f'color{i+1}_weight'] = c['weight']\n",
    "            color_results.append(entry)\n",
    "        else:\n",
    "            error_counter[error] += 1\n",
    "            failed_records.append({\n",
    "                'product_id': row[COL_PRODUCT_ID],\n",
    "                'url': url,\n",
    "                'label': row['label_extracted'],\n",
    "                'error': error,\n",
    "            })\n",
    "\n",
    "        if (idx + 1) % SAVE_EVERY == 0 and color_results:\n",
    "            total_in_cache = save_incremental(color_results, COLOR_CACHE_PATH)\n",
    "            print(f\"  [checkpoint] {total_in_cache:,} products in cache\")\n",
    "\n",
    "    # Final save\n",
    "    print(f\"\\nSaving...\")\n",
    "    if color_results:\n",
    "        total_in_cache = save_incremental(color_results, COLOR_CACHE_PATH)\n",
    "        print(f\"  Cache: {total_in_cache:,} products -> {COLOR_CACHE_PATH}\")\n",
    "\n",
    "    if failed_records:\n",
    "        pd.DataFrame(failed_records).to_csv(FAILED_URLS_PATH, index=False)\n",
    "        print(f\"  Failed URLs log -> {FAILED_URLS_PATH}\")\n",
    "\n",
    "    # Summary\n",
    "    total = len(to_extract)\n",
    "    success_count = len(color_results)\n",
    "    success_rate = 100 * success_count / total if total else 0\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Processed: {total:,}\")\n",
    "    print(f\"Extracted: {success_count:,} ({success_rate:.1f}%)\")\n",
    "    print(f\"Failed:    {total - success_count:,} ({100 - success_rate:.1f}%)\")\n",
    "\n",
    "    print(\"\\nFailure breakdown:\")\n",
    "    for error, count in error_counter.most_common(10):\n",
    "        print(f\"  {error}: {count} ({100*count/total:.1f}%)\")\n",
    "\n",
    "    print(\"\\nPer-domain results:\")\n",
    "    print(f\"  {'domain':<40s} {'ok':>5s} / {'total':>5s}  {'rate':>6s}\")\n",
    "    print(f\"  {'-'*60}\")\n",
    "    for domain, (ok, tot, rate) in domain_tracker.summary().items():\n",
    "        print(f\"  {domain:<40s} {ok:>5d} / {tot:>5d}  {rate:>5.0%}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STAGE 2: ML GENDER PREDICTION\n",
    "# ============================================================================\n",
    "\n",
    "def run_ml_pipeline():\n",
    "    \"\"\"Stage 2: train classifiers, predict gender, export validation sample.\"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.linear_model import LogisticRegressionCV\n",
    "    from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "    from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "    CHART_ML_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    TEXT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"STAGE 2: ML GENDER PREDICTION PIPELINE\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # ---- Load data ----\n",
    "    df = load_main_data()\n",
    "    print(f\"Main dataset: {len(df):,} products\")\n",
    "\n",
    "    human_coded = pd.read_csv(PATH_HUMAN_CODED, encoding='latin-1')\n",
    "    human_coded.columns = human_coded.columns.str.lower().str.strip().str.replace(' ', '_')\n",
    "    if 'unnamed:_0' in human_coded.columns:\n",
    "        human_coded = human_coded.drop(columns=['unnamed:_0'])\n",
    "    print(f\"Human-coded: {len(human_coded)} products\")\n",
    "\n",
    "    try:\n",
    "        your_labeled = pd.read_excel(PATH_YOUR_LABELED)\n",
    "        your_labeled.columns = your_labeled.columns.str.lower().str.strip().str.replace(' ', '_')\n",
    "        print(f\"Your labeled: {len(your_labeled)} products\")\n",
    "    except FileNotFoundError:\n",
    "        your_labeled = pd.DataFrame()\n",
    "        print(\"Your labeled file not found (optional)\")\n",
    "\n",
    "    # ---- Filter and label ----\n",
    "    original_count = len(df)\n",
    "    df = filter_excluded_categories(df)\n",
    "    excluded_count = original_count - len(df)\n",
    "    print(f\"Filtered: {original_count:,} -> {len(df):,} (excluded {excluded_count:,})\")\n",
    "\n",
    "    df = add_gender_labels(df)\n",
    "    print(f\"Label distribution: {df['label_extracted'].value_counts().to_dict()}\")\n",
    "\n",
    "    # Merge human labels\n",
    "    if 'human_gender_label' in human_coded.columns and COL_PRODUCT_ID in human_coded.columns:\n",
    "        human_labels = human_coded[[COL_PRODUCT_ID, 'human_gender_label']].drop_duplicates()\n",
    "        human_labels.columns = [COL_PRODUCT_ID, 'label_human']\n",
    "        human_labels['label_human'] = human_labels['label_human'].str.lower().str.strip()\n",
    "        df = df.merge(human_labels, on=COL_PRODUCT_ID, how='left')\n",
    "    else:\n",
    "        df['label_human'] = None\n",
    "    print(f\"Human labels merged: {df['label_human'].notna().sum()}\")\n",
    "\n",
    "    # ---- Load color cache ----\n",
    "    if COLOR_CACHE_PATH.exists():\n",
    "        color_df = pd.read_csv(COLOR_CACHE_PATH)\n",
    "        print(f\"Color cache: {len(color_df):,} products\")\n",
    "        matched = color_df[COL_PRODUCT_ID].isin(df[COL_PRODUCT_ID]).sum()\n",
    "        print(f\"  Matched to filtered data: {matched:,} / {len(color_df):,}\")\n",
    "    else:\n",
    "        print(\"No color cache found -- proceeding without color features\")\n",
    "        color_df = pd.DataFrame()\n",
    "\n",
    "    # ---- Training data ----\n",
    "    female_all = df[df['label_extracted'] == 'female'].copy()\n",
    "    male_all = df[df['label_extracted'] == 'male'].copy()\n",
    "    print(f\"\\nExplicitly female: {len(female_all)}, male: {len(male_all)}\")\n",
    "\n",
    "    if len(female_all) < MIN_CLASS_SIZE or len(male_all) < MIN_CLASS_SIZE:\n",
    "        raise ValueError(f\"Insufficient gendered samples (need >= {MIN_CLASS_SIZE} per class).\")\n",
    "\n",
    "    human_none = df[df['label_human'] == 'none'].copy()\n",
    "    extracted_none = df[(df['label_extracted'] == 'none') & (df['label_human'].isna())].copy()\n",
    "    min_gendered = min(len(female_all), len(male_all))\n",
    "    target_none = min_gendered\n",
    "\n",
    "    if len(human_none) >= target_none:\n",
    "        none_all = human_none.sample(n=target_none, random_state=RANDOM_STATE)\n",
    "    else:\n",
    "        remaining = target_none - len(human_none)\n",
    "        sampled_none = extracted_none.sample(\n",
    "            n=min(remaining, len(extracted_none)), random_state=RANDOM_STATE)\n",
    "        none_all = pd.concat([human_none, sampled_none])\n",
    "\n",
    "    min_class = min(len(female_all), len(male_all), len(none_all))\n",
    "    print(f\"Balancing to: {min_class} per class\")\n",
    "\n",
    "    female_balanced = female_all.sample(n=min_class, random_state=RANDOM_STATE)\n",
    "    male_balanced = male_all.sample(n=min_class, random_state=RANDOM_STATE)\n",
    "    none_balanced = none_all.sample(n=min_class, random_state=RANDOM_STATE)\n",
    "\n",
    "    ml_data = pd.concat([female_balanced, male_balanced, none_balanced]).copy()\n",
    "    ml_data['target'] = ml_data['label_extracted'].map({'female': 0, 'male': 1})\n",
    "    ml_data.loc[ml_data['target'].isna(), 'target'] = 2\n",
    "    ml_data['target'] = ml_data['target'].astype(int)\n",
    "    print(f\"Training data: {len(ml_data)} (classes: {ml_data['target'].value_counts().sort_index().to_dict()})\")\n",
    "\n",
    "    # ---- Train/test split ----\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        ml_data.index, test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE, stratify=ml_data['target'],\n",
    "    )\n",
    "    train_data = ml_data.loc[train_idx].copy()\n",
    "    test_data = ml_data.loc[test_idx].copy()\n",
    "    print(f\"Train: {len(train_data)}, Test: {len(test_data)}\")\n",
    "\n",
    "    # ---- Feature engineering ----\n",
    "    all_datasets = [train_data, test_data, df]\n",
    "    for dataset in all_datasets:\n",
    "        dataset['breadcrumb_clean'] = dataset[COL_BREADCRUMB].apply(clean_text_remove_gender)\n",
    "        dataset['description_clean'] = dataset[COL_DESC].apply(clean_text_remove_gender)\n",
    "\n",
    "    # Price features\n",
    "    price_features = ['feat_price_log', 'feat_unit_price']\n",
    "    for dataset in all_datasets:\n",
    "        dataset['feat_price'] = pd.to_numeric(dataset[COL_PRICE], errors='coerce')\n",
    "        dataset['feat_price_log'] = np.log1p(dataset['feat_price'])\n",
    "        if COL_UNIT_PRICE in dataset.columns:\n",
    "            dataset['feat_unit_price'] = (\n",
    "                dataset[COL_UNIT_PRICE].astype(str).str.extract(r'([\\d.]+)')[0].astype(float))\n",
    "        else:\n",
    "            dataset['feat_unit_price'] = 0\n",
    "\n",
    "    # Store encoding\n",
    "    store_encoder = LabelEncoder()\n",
    "    all_stores = pd.concat([d[COL_STORE] for d in all_datasets]).fillna('unknown')\n",
    "    store_encoder.fit(all_stores.unique())\n",
    "\n",
    "    def encode_stores(data, encoder):\n",
    "        stores = data[COL_STORE].fillna('unknown')\n",
    "        encoded = []\n",
    "        for s in stores:\n",
    "            if s in encoder.classes_:\n",
    "                encoded.append(encoder.transform([s])[0])\n",
    "            else:\n",
    "                encoded.append(-1)\n",
    "        return np.array(encoded)\n",
    "\n",
    "    for dataset in all_datasets:\n",
    "        dataset['store_encoded'] = encode_stores(dataset, store_encoder)\n",
    "    n_stores = len(store_encoder.classes_) + 1\n",
    "\n",
    "    # TF-IDF (fit on train only)\n",
    "    breadcrumb_vectorizer = TfidfVectorizer(\n",
    "        max_features=80, min_df=8, max_df=0.8, ngram_range=(1, 1), stop_words='english')\n",
    "    breadcrumb_vectorizer.fit(train_data['breadcrumb_clean'])\n",
    "\n",
    "    description_vectorizer = TfidfVectorizer(\n",
    "        max_features=150, min_df=8, max_df=0.8, ngram_range=(1, 1), stop_words='english')\n",
    "    description_vectorizer.fit(train_data['description_clean'])\n",
    "\n",
    "    print(f\"Breadcrumb TF-IDF: {len(breadcrumb_vectorizer.get_feature_names_out())} features\")\n",
    "    print(f\"Description TF-IDF: {len(description_vectorizer.get_feature_names_out())} features\")\n",
    "\n",
    "    # Color features\n",
    "    color_feature_cols = []\n",
    "    for color_name in STANDARD_COLORS.keys():\n",
    "        for i in range(1, N_COLORS + 1):\n",
    "            color_feature_cols.append(f'feat_color{i}_{color_name}')\n",
    "\n",
    "    for dataset in all_datasets:\n",
    "        for col in color_feature_cols:\n",
    "            dataset[col] = 0.0\n",
    "\n",
    "    color_lookup = {}\n",
    "    if len(color_df) > 0 and COL_PRODUCT_ID in color_df.columns:\n",
    "        for _, row in color_df.iterrows():\n",
    "            pid = row[COL_PRODUCT_ID]\n",
    "            feats = {}\n",
    "            for i in range(1, N_COLORS + 1):\n",
    "                cname = row.get(f'color{i}_name')\n",
    "                cweight = row.get(f'color{i}_weight')\n",
    "                if pd.notna(cname) and cname in STANDARD_COLORS and pd.notna(cweight):\n",
    "                    feats[f'feat_color{i}_{cname}'] = cweight\n",
    "            if feats:\n",
    "                color_lookup[pid] = feats\n",
    "\n",
    "        print(f\"Color lookup built: {len(color_lookup):,} products\")\n",
    "        for dataset in all_datasets:\n",
    "            matched = 0\n",
    "            for idx_row, row in dataset.iterrows():\n",
    "                pid = row[COL_PRODUCT_ID]\n",
    "                if pid in color_lookup:\n",
    "                    for col, val in color_lookup[pid].items():\n",
    "                        dataset.at[idx_row, col] = val\n",
    "                    matched += 1\n",
    "            if len(dataset) < 10000:\n",
    "                print(f\"  Color features filled for {matched}/{len(dataset)} rows\")\n",
    "\n",
    "    train_has_color = sum(1 for _, r in train_data.iterrows() if r[COL_PRODUCT_ID] in color_lookup)\n",
    "    print(f\"Color features: {len(color_feature_cols)} \"\n",
    "          f\"(available for {train_has_color}/{len(train_data)} train samples)\")\n",
    "\n",
    "    # ---- Build feature matrices ----\n",
    "    def build_feature_matrix(data, bc_vec, desc_vec, color_cols, p_features,\n",
    "                             ns, include_colors=True):\n",
    "        feature_names = []\n",
    "        blocks = []\n",
    "\n",
    "        X_price = data[p_features].fillna(0).values\n",
    "        blocks.append(csr_matrix(X_price))\n",
    "        feature_names.extend(p_features)\n",
    "\n",
    "        store_enc = data['store_encoded'].values\n",
    "        X_store = np.zeros((len(data), ns))\n",
    "        for i, s in enumerate(store_enc):\n",
    "            if s >= 0:\n",
    "                X_store[i, s] = 1\n",
    "            else:\n",
    "                X_store[i, -1] = 1\n",
    "        blocks.append(csr_matrix(X_store))\n",
    "        feature_names.extend([f'store_{i}' for i in range(ns)])\n",
    "\n",
    "        X_bc = bc_vec.transform(data['breadcrumb_clean'])\n",
    "        blocks.append(X_bc)\n",
    "        feature_names.extend([f'bc_{f}' for f in bc_vec.get_feature_names_out()])\n",
    "\n",
    "        X_desc = desc_vec.transform(data['description_clean'])\n",
    "        blocks.append(X_desc)\n",
    "        feature_names.extend([f'desc_{f}' for f in desc_vec.get_feature_names_out()])\n",
    "\n",
    "        if include_colors:\n",
    "            X_color = data[color_cols].values\n",
    "            blocks.append(csr_matrix(X_color))\n",
    "            feature_names.extend(color_cols)\n",
    "\n",
    "        return hstack(blocks), feature_names\n",
    "\n",
    "    X_train, feature_names = build_feature_matrix(\n",
    "        train_data, breadcrumb_vectorizer, description_vectorizer,\n",
    "        color_feature_cols, price_features, n_stores)\n",
    "    X_test, _ = build_feature_matrix(\n",
    "        test_data, breadcrumb_vectorizer, description_vectorizer,\n",
    "        color_feature_cols, price_features, n_stores)\n",
    "\n",
    "    y_train = train_data['target'].values\n",
    "    y_test = test_data['target'].values\n",
    "    print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "\n",
    "    # ---- Train models ----\n",
    "    results = []\n",
    "\n",
    "    print(\"\\n--- Logistic Regression (L1) ---\")\n",
    "    model_l1 = LogisticRegressionCV(\n",
    "        cv=CV_FOLDS, penalty='l1', solver='saga', max_iter=2000,\n",
    "        multi_class='multinomial', class_weight='balanced', random_state=RANDOM_STATE)\n",
    "    model_l1.fit(X_train, y_train)\n",
    "    y_pred_l1 = model_l1.predict(X_test)\n",
    "    acc_l1 = accuracy_score(y_test, y_pred_l1)\n",
    "    f1_l1 = f1_score(y_test, y_pred_l1, average='weighted')\n",
    "    print(f\"Accuracy: {acc_l1:.4f}, F1: {f1_l1:.4f}\")\n",
    "    results.append({'Model': 'L1 (LASSO)', 'Accuracy': acc_l1, 'F1_weighted': f1_l1})\n",
    "\n",
    "    print(\"\\n--- Logistic Regression (L2) ---\")\n",
    "    model_l2 = LogisticRegressionCV(\n",
    "        cv=CV_FOLDS, penalty='l2', solver='lbfgs', max_iter=2000,\n",
    "        multi_class='multinomial', class_weight='balanced', random_state=RANDOM_STATE)\n",
    "    model_l2.fit(X_train, y_train)\n",
    "    y_pred_l2 = model_l2.predict(X_test)\n",
    "    acc_l2 = accuracy_score(y_test, y_pred_l2)\n",
    "    f1_l2 = f1_score(y_test, y_pred_l2, average='weighted')\n",
    "    print(f\"Accuracy: {acc_l2:.4f}, F1: {f1_l2:.4f}\")\n",
    "    results.append({'Model': 'L2 (Ridge)', 'Accuracy': acc_l2, 'F1_weighted': f1_l2})\n",
    "\n",
    "    print(\"\\n--- Random Forest ---\")\n",
    "    model_rf = RandomForestClassifier(\n",
    "        n_estimators=200, max_depth=15, min_samples_split=10, min_samples_leaf=5,\n",
    "        class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = model_rf.predict(X_test)\n",
    "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "    print(f\"Accuracy: {acc_rf:.4f}, F1: {f1_rf:.4f}\")\n",
    "    results.append({'Model': 'Random Forest', 'Accuracy': acc_rf, 'F1_weighted': f1_rf})\n",
    "\n",
    "    print(\"\\n--- Histogram Gradient Boosting ---\")\n",
    "    MAX_HGB_SAMPLES = 50000\n",
    "    if X_train.shape[0] > MAX_HGB_SAMPLES:\n",
    "        sample_idx = np.random.choice(X_train.shape[0], MAX_HGB_SAMPLES, replace=False)\n",
    "        X_train_hgb = X_train[sample_idx].toarray()\n",
    "        y_train_hgb = y_train[sample_idx]\n",
    "    else:\n",
    "        X_train_hgb = X_train.toarray()\n",
    "        y_train_hgb = y_train\n",
    "\n",
    "    model_hgb = HistGradientBoostingClassifier(\n",
    "        max_iter=200, max_depth=10, learning_rate=0.1, random_state=RANDOM_STATE)\n",
    "    model_hgb.fit(X_train_hgb, y_train_hgb)\n",
    "    y_pred_hgb = model_hgb.predict(X_test.toarray())\n",
    "    acc_hgb = accuracy_score(y_test, y_pred_hgb)\n",
    "    f1_hgb = f1_score(y_test, y_pred_hgb, average='weighted')\n",
    "    print(f\"Accuracy: {acc_hgb:.4f}, F1: {f1_hgb:.4f}\")\n",
    "    results.append({'Model': 'Hist Gradient Boosting', 'Accuracy': acc_hgb, 'F1_weighted': f1_hgb})\n",
    "\n",
    "    print(\"\\n--- SVM (RBF) ---\")\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model_svm = SVC(\n",
    "        kernel='rbf', C=1.0, gamma='scale', class_weight='balanced',\n",
    "        probability=True, random_state=RANDOM_STATE)\n",
    "    model_svm.fit(X_train_scaled, y_train)\n",
    "    y_pred_svm = model_svm.predict(X_test_scaled)\n",
    "    acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "    print(f\"Accuracy: {acc_svm:.4f}, F1: {f1_svm:.4f}\")\n",
    "    results.append({'Model': 'SVM', 'Accuracy': acc_svm, 'F1_weighted': f1_svm})\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values('F1_weighted', ascending=False)\n",
    "    print(f\"\\n{'='*70}\\nMODEL COMPARISON\\n{'='*70}\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    results_df.to_csv(TEXT_DIR / 'model_comparison.csv', index=False)\n",
    "\n",
    "    # ---- Best model analysis ----\n",
    "    best_name = results_df.iloc[0]['Model']\n",
    "    print(f\"\\nBest model: {best_name}\")\n",
    "\n",
    "    model_map = {\n",
    "        'L1': (model_l1, y_pred_l1), 'L2': (model_l2, y_pred_l2),\n",
    "        'Random': (model_rf, y_pred_rf), 'Hist': (model_hgb, y_pred_hgb),\n",
    "        'SVM': (model_svm, y_pred_svm),\n",
    "    }\n",
    "    best_model, y_pred_best = model_l1, y_pred_l1  # default\n",
    "    for key, (model, preds) in model_map.items():\n",
    "        if key in best_name:\n",
    "            best_model, y_pred_best = model, preds\n",
    "            break\n",
    "\n",
    "    if len(np.unique(y_test)) == 3:\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred_best, target_names=['female', 'male', 'none']))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred_best, labels=[0, 1, 2])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(f\"            Predicted\")\n",
    "    print(f\"            female  male  none\")\n",
    "    for i, label in enumerate(['female', 'male', 'none']):\n",
    "        row = cm[i] if i < len(cm) else [0, 0, 0]\n",
    "        print(f\"Actual {label:6s}  {row[0]:4d}  {row[1]:4d}  {row[2]:4d}\")\n",
    "\n",
    "    # ---- Feature importance ----\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'coef_female': model_l1.coef_[0],\n",
    "        'coef_male': model_l1.coef_[1],\n",
    "        'coef_none': model_l1.coef_[2],\n",
    "    })\n",
    "    importance_df['max_abs'] = importance_df[['coef_female', 'coef_male', 'coef_none']].abs().max(axis=1)\n",
    "    importance_df = importance_df.sort_values('max_abs', ascending=False)\n",
    "\n",
    "    for label, col in [('FEMALE', 'coef_female'), ('MALE', 'coef_male'), ('NONE', 'coef_none')]:\n",
    "        top = importance_df[importance_df[col] > 0].nlargest(15, col)\n",
    "        print(f\"\\nTop 15 {label} features:\")\n",
    "        for _, row in top.iterrows():\n",
    "            print(f\"  {row['feature']:40s}: {row[col]:+.4f}\")\n",
    "\n",
    "    importance_df.to_csv(TEXT_DIR / 'feature_importance.csv', index=False)\n",
    "\n",
    "    # ---- Predict on all products ----\n",
    "    X_all, _ = build_feature_matrix(\n",
    "        df, breadcrumb_vectorizer, description_vectorizer,\n",
    "        color_feature_cols, price_features, n_stores)\n",
    "\n",
    "    df['ml_prob_female'] = model_l1.predict_proba(X_all)[:, 0]\n",
    "    df['ml_prob_male'] = model_l1.predict_proba(X_all)[:, 1]\n",
    "    df['ml_prob_none'] = model_l1.predict_proba(X_all)[:, 2]\n",
    "    df['ml_pred'] = model_l1.predict(X_all)\n",
    "    df['ml_pred_label'] = df['ml_pred'].map({0: 'female', 1: 'male', 2: 'none'})\n",
    "    df['ml_confidence'] = df[['ml_prob_female', 'ml_prob_male', 'ml_prob_none']].max(axis=1)\n",
    "\n",
    "    print(f\"\\nPrediction distribution:\\n{df['ml_pred_label'].value_counts()}\")\n",
    "\n",
    "    # ---- Color feature impact ----\n",
    "    X_train_no_color, _ = build_feature_matrix(\n",
    "        train_data, breadcrumb_vectorizer, description_vectorizer,\n",
    "        color_feature_cols, price_features, n_stores, include_colors=False)\n",
    "    X_test_no_color, _ = build_feature_matrix(\n",
    "        test_data, breadcrumb_vectorizer, description_vectorizer,\n",
    "        color_feature_cols, price_features, n_stores, include_colors=False)\n",
    "\n",
    "    model_no_color = LogisticRegressionCV(\n",
    "        cv=CV_FOLDS, penalty='l1', solver='saga', max_iter=2000,\n",
    "        multi_class='multinomial', class_weight='balanced', random_state=RANDOM_STATE)\n",
    "    model_no_color.fit(X_train_no_color, y_train)\n",
    "    y_pred_no_color = model_no_color.predict(X_test_no_color)\n",
    "\n",
    "    acc_no_color = accuracy_score(y_test, y_pred_no_color)\n",
    "    f1_no_color = f1_score(y_test, y_pred_no_color, average='weighted')\n",
    "    print(f\"\\nColor impact:\")\n",
    "    print(f\"  WITH colors:    Accuracy={acc_l1:.4f}, F1={f1_l1:.4f}\")\n",
    "    print(f\"  WITHOUT colors: Accuracy={acc_no_color:.4f}, F1={f1_no_color:.4f}\")\n",
    "    print(f\"  Delta:          Accuracy {(acc_l1-acc_no_color)*100:+.2f}pp, \"\n",
    "          f\"F1 {(f1_l1-f1_no_color)*100:+.2f}pp\")\n",
    "\n",
    "    # ---- Morrisons-only HGB color ablation (fairer test) ----\n",
    "    # The above comparison underestimates color's contribution because:\n",
    "    #   - It uses L1 (weakest model) instead of HGB (best model)\n",
    "    #   - Most training rows have zero-filled color columns (Tesco/ASDA)\n",
    "    # Here we restrict to products with actual color data and use HGB.\n",
    "    morrisons_pids = set(color_df[COL_PRODUCT_ID].values) if len(color_df) > 0 else set()\n",
    "    train_morr = train_data[train_data[COL_PRODUCT_ID].isin(morrisons_pids)]\n",
    "    test_morr = test_data[test_data[COL_PRODUCT_ID].isin(morrisons_pids)]\n",
    "\n",
    "    if len(train_morr) >= 30 and len(test_morr) >= 10:\n",
    "        print(f\"\\nMorrisons-only color ablation (HGB):  train={len(train_morr)}, test={len(test_morr)}\")\n",
    "        y_train_morr = train_morr['target'].values\n",
    "        y_test_morr = test_morr['target'].values\n",
    "\n",
    "        # With color\n",
    "        X_train_morr_wc, _ = build_feature_matrix(\n",
    "            train_morr, breadcrumb_vectorizer, description_vectorizer,\n",
    "            color_feature_cols, price_features, n_stores, include_colors=True)\n",
    "        X_test_morr_wc, _ = build_feature_matrix(\n",
    "            test_morr, breadcrumb_vectorizer, description_vectorizer,\n",
    "            color_feature_cols, price_features, n_stores, include_colors=True)\n",
    "\n",
    "        hgb_morr_wc = HistGradientBoostingClassifier(\n",
    "            max_iter=200, max_depth=10, learning_rate=0.1, random_state=RANDOM_STATE)\n",
    "        hgb_morr_wc.fit(X_train_morr_wc.toarray(), y_train_morr)\n",
    "        pred_morr_wc = hgb_morr_wc.predict(X_test_morr_wc.toarray())\n",
    "        acc_morr_wc = accuracy_score(y_test_morr, pred_morr_wc)\n",
    "        f1_morr_wc = f1_score(y_test_morr, pred_morr_wc, average='weighted')\n",
    "\n",
    "        # Without color\n",
    "        X_train_morr_nc, _ = build_feature_matrix(\n",
    "            train_morr, breadcrumb_vectorizer, description_vectorizer,\n",
    "            color_feature_cols, price_features, n_stores, include_colors=False)\n",
    "        X_test_morr_nc, _ = build_feature_matrix(\n",
    "            test_morr, breadcrumb_vectorizer, description_vectorizer,\n",
    "            color_feature_cols, price_features, n_stores, include_colors=False)\n",
    "\n",
    "        hgb_morr_nc = HistGradientBoostingClassifier(\n",
    "            max_iter=200, max_depth=10, learning_rate=0.1, random_state=RANDOM_STATE)\n",
    "        hgb_morr_nc.fit(X_train_morr_nc.toarray(), y_train_morr)\n",
    "        pred_morr_nc = hgb_morr_nc.predict(X_test_morr_nc.toarray())\n",
    "        acc_morr_nc = accuracy_score(y_test_morr, pred_morr_nc)\n",
    "        f1_morr_nc = f1_score(y_test_morr, pred_morr_nc, average='weighted')\n",
    "\n",
    "        morr_delta_acc = (acc_morr_wc - acc_morr_nc) * 100\n",
    "        morr_delta_f1 = (f1_morr_wc - f1_morr_nc) * 100\n",
    "\n",
    "        print(f\"  HGB WITH colors:    Accuracy={acc_morr_wc:.4f}, F1={f1_morr_wc:.4f}\")\n",
    "        print(f\"  HGB WITHOUT colors: Accuracy={acc_morr_nc:.4f}, F1={f1_morr_nc:.4f}\")\n",
    "        print(f\"  Delta (Morrisons HGB): Accuracy {morr_delta_acc:+.2f}pp, F1 {morr_delta_f1:+.2f}pp\")\n",
    "\n",
    "        # Save to summary later\n",
    "        morr_color_ablation = {\n",
    "            'n_train': int(len(train_morr)),\n",
    "            'n_test': int(len(test_morr)),\n",
    "            'hgb_with_colors_acc': float(acc_morr_wc),\n",
    "            'hgb_with_colors_f1': float(f1_morr_wc),\n",
    "            'hgb_without_colors_acc': float(acc_morr_nc),\n",
    "            'hgb_without_colors_f1': float(f1_morr_nc),\n",
    "            'delta_acc_pp': float(morr_delta_acc),\n",
    "            'delta_f1_pp': float(morr_delta_f1),\n",
    "        }\n",
    "    else:\n",
    "        print(f\"\\nMorrisons-only ablation skipped: insufficient data \"\n",
    "              f\"(train={len(train_morr)}, test={len(test_morr)})\")\n",
    "        morr_color_ablation = None\n",
    "\n",
    "    # ---- Validation vs human labels ----\n",
    "    human_labeled = df[df['label_human'].notna()].copy()\n",
    "    print(f\"\\nProducts with human labels: {len(human_labeled)}\")\n",
    "    if len(human_labeled) > 0:\n",
    "        human_labeled['human_encoded'] = human_labeled['label_human'].map(\n",
    "            {'female': 0, 'male': 1, 'none': 2})\n",
    "        valid = human_labeled[human_labeled['human_encoded'].notna()]\n",
    "        if len(valid) >= MIN_TEST_SAMPLES:\n",
    "            acc_human = accuracy_score(valid['human_encoded'], valid['ml_pred'])\n",
    "            print(f\"Accuracy vs human: {acc_human:.4f}\")\n",
    "\n",
    "    # ---- Implicit gendering ----\n",
    "    implicit_female = df[\n",
    "        (df['label_extracted'] == 'none') &\n",
    "        (df['ml_pred_label'] == 'female') &\n",
    "        (df['ml_confidence'] > 0.5)]\n",
    "    implicit_male = df[\n",
    "        (df['label_extracted'] == 'none') &\n",
    "        (df['ml_pred_label'] == 'male') &\n",
    "        (df['ml_confidence'] > 0.5)]\n",
    "\n",
    "    print(f\"\\nImplicit female (>50% conf): {len(implicit_female):,}\")\n",
    "    print(f\"Implicit male (>50% conf): {len(implicit_male):,}\")\n",
    "\n",
    "    # ---- Export validation sample ----\n",
    "    already_labeled = set()\n",
    "    if COL_PRODUCT_ID in human_coded.columns:\n",
    "        already_labeled.update(human_coded[COL_PRODUCT_ID].values)\n",
    "    if len(your_labeled) > 0 and COL_PRODUCT_ID in your_labeled.columns:\n",
    "        already_labeled.update(your_labeled[COL_PRODUCT_ID].values)\n",
    "\n",
    "    available = df[\n",
    "        (~df[COL_PRODUCT_ID].isin(already_labeled)) & (df[COL_IMAGE].notna())].copy()\n",
    "    print(f\"\\nAvailable for validation: {len(available):,}\")\n",
    "\n",
    "    if len(available) > 0:\n",
    "        N_PER = 85\n",
    "        samples = []\n",
    "        for pred, label in [(0, 'female'), (1, 'male'), (2, 'none')]:\n",
    "            pool = available[available['ml_pred'] == pred]\n",
    "            n = min(N_PER, len(pool))\n",
    "            if n > 0:\n",
    "                samples.append(pool.sample(n=n, random_state=RANDOM_STATE))\n",
    "                print(f\"  Sampled {n} {label}\")\n",
    "\n",
    "        if samples:\n",
    "            validation = pd.concat(samples).sample(frac=1, random_state=RANDOM_STATE)\n",
    "            export_cols = [\n",
    "                COL_PRODUCT_ID, COL_NAME, COL_DESC, COL_BREADCRUMB, COL_IMAGE,\n",
    "                COL_URL, COL_PRICE, 'label_extracted', 'ml_pred_label',\n",
    "                'ml_prob_female', 'ml_prob_male', 'ml_prob_none', 'ml_confidence',\n",
    "            ]\n",
    "            export_cols = [c for c in export_cols if c in validation.columns]\n",
    "            validation_export = validation[export_cols].copy()\n",
    "            validation_export['manual_gender'] = ''\n",
    "            validation_export['manual_confidence'] = ''\n",
    "            validation_export['manual_notes'] = ''\n",
    "            validation_export.to_csv(TEXT_DIR / 'validation_sample.csv', index=True)\n",
    "            print(f\"Saved validation sample: {len(validation_export)} products\")\n",
    "\n",
    "    # ---- Summary ----\n",
    "    summary = {\n",
    "        'version': '4.0',\n",
    "        'data': {\n",
    "            'original': original_count,\n",
    "            'filtered': int(len(df)),\n",
    "            'excluded': int(excluded_count),\n",
    "            'training_samples': int(len(ml_data)),\n",
    "            'color_samples': int(len(color_df)),\n",
    "            'color_coverage_note': 'Morrisons only; Tesco/ASDA CDN links expired',\n",
    "        },\n",
    "        'models': results,\n",
    "        'color_impact': {\n",
    "            'full_sample_l1': {\n",
    "                'with_colors_f1': float(f1_l1),\n",
    "                'without_colors_f1': float(f1_no_color),\n",
    "            },\n",
    "            'morrisons_only_hgb': morr_color_ablation,\n",
    "        },\n",
    "        'predictions': {\n",
    "            'female': int((df['ml_pred_label'] == 'female').sum()),\n",
    "            'male': int((df['ml_pred_label'] == 'male').sum()),\n",
    "            'none': int((df['ml_pred_label'] == 'none').sum()),\n",
    "        },\n",
    "    }\n",
    "    with open(TEXT_DIR / 'summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"\\nPipeline complete. Charts in {CHART_ML_DIR}, tables in {TEXT_DIR}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STAGE 3: REGRESSION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def run_regression_analysis():\n",
    "    \"\"\"Stage 3: OLS, quantile, within-category, and by-store regressions.\"\"\"\n",
    "    import statsmodels.api as sm\n",
    "    import statsmodels.formula.api as smf\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    CHART_REG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"STAGE 3: REGRESSION ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # ---- Load and prepare ----\n",
    "    df = load_main_data()\n",
    "    df = filter_excluded_categories(df)\n",
    "\n",
    "    for col_label, col_source in [('label_bc', COL_BREADCRUMB),\n",
    "                                   ('label_name', COL_NAME),\n",
    "                                   ('label_desc', COL_DESC)]:\n",
    "        df[col_label] = df[col_source].apply(extract_gender_from_text)\n",
    "\n",
    "    def combine_labels(row):\n",
    "        for col in ['label_bc', 'label_name', 'label_desc']:\n",
    "            if row[col] in ('female', 'male'):\n",
    "                return row[col]\n",
    "        return 'none'\n",
    "\n",
    "    df['gender'] = df.apply(combine_labels, axis=1)\n",
    "\n",
    "    df['price_num'] = pd.to_numeric(df[COL_PRICE], errors='coerce')\n",
    "    df = df[df['price_num'].notna() & (df['price_num'] > 0)].copy()\n",
    "    df['log_price'] = np.log(df['price_num'])\n",
    "\n",
    "    if COL_UNIT_PRICE in df.columns:\n",
    "        df['unit_price_num'] = df[COL_UNIT_PRICE].astype(str).str.extract(r'([\\d.]+)')[0].astype(float)\n",
    "\n",
    "    df['store'] = df[COL_STORE].fillna('unknown').astype(str)\n",
    "\n",
    "    # Infer store names\n",
    "    store_names = {}\n",
    "    for sid in df['store'].unique():\n",
    "        sub = df[df['store'] == sid]\n",
    "        bc_sample = sub[COL_BREADCRUMB].dropna().head(10).str.lower()\n",
    "        if bc_sample.str.contains('morrisons').any():\n",
    "            store_names[sid] = 'Morrisons'\n",
    "        elif bc_sample.str.contains('tesco').any():\n",
    "            store_names[sid] = 'Tesco'\n",
    "        elif bc_sample.str.contains('asda').any():\n",
    "            store_names[sid] = 'ASDA'\n",
    "        else:\n",
    "            store_names[sid] = f'Store {sid}'\n",
    "    df['store_name'] = df['store'].map(store_names)\n",
    "\n",
    "    # Breadcrumb parsing\n",
    "    df[['cat1', 'cat2', 'cat3']] = df[COL_BREADCRUMB].apply(\n",
    "        lambda x: pd.Series(parse_breadcrumb(x)))\n",
    "    df['cat_broad'] = df['cat1']\n",
    "    df['cat_mid'] = df['cat1'] + ' > ' + df['cat2']\n",
    "    df['cat_fine'] = df['cat1'] + ' > ' + df['cat2'] + ' > ' + df['cat3']\n",
    "\n",
    "    print(f\"Products with valid prices: {len(df):,}\")\n",
    "    print(f\"\\nGender distribution:\")\n",
    "    for g in ['female', 'male', 'none', 'both']:\n",
    "        sub = df[df['gender'] == g]\n",
    "        if len(sub) > 0:\n",
    "            print(f\"  {g}: {len(sub):,}  (mean {sub['price_num'].mean():.2f}, \"\n",
    "                  f\"median {sub['price_num'].median():.2f})\")\n",
    "\n",
    "    # ---- Analysis sample ----\n",
    "    gendered = df[df['gender'].isin(['female', 'male'])].copy()\n",
    "    gendered['is_female'] = (gendered['gender'] == 'female').astype(int)\n",
    "    print(f\"\\nGendered sample: N = {len(gendered):,} \"\n",
    "          f\"(F: {gendered['is_female'].sum()}, M: {(1-gendered['is_female']).sum()})\")\n",
    "\n",
    "    # ---- Regressions ----\n",
    "    results_table = []\n",
    "\n",
    "    def run_and_record(name, formula, data, controls, coef_name='is_female'):\n",
    "        model = smf.ols(formula, data=data).fit(cov_type='HC1')\n",
    "        coef = model.params[coef_name]\n",
    "        se = model.bse[coef_name]\n",
    "        pval = model.pvalues[coef_name]\n",
    "        pct = (np.exp(coef) - 1) * 100\n",
    "        ci_lo = coef - 1.96 * se\n",
    "        ci_hi = coef + 1.96 * se\n",
    "        results_table.append({\n",
    "            'spec': name, 'coef': coef, 'se': se, 'p': pval, 'pct': pct,\n",
    "            'ci_lo': ci_lo, 'ci_hi': ci_hi,\n",
    "            'pct_lo': (np.exp(ci_lo) - 1) * 100,\n",
    "            'pct_hi': (np.exp(ci_hi) - 1) * 100,\n",
    "            'r2': model.rsquared, 'n': int(model.nobs), 'controls': controls,\n",
    "        })\n",
    "        sig = '***' if pval < 0.01 else ('**' if pval < 0.05 else ('*' if pval < 0.1 else ''))\n",
    "        print(f\"  {name}: coef={coef:+.4f} ({pct:+.1f}%), SE={se:.4f}, \"\n",
    "              f\"p={pval:.4f}{sig}, R2={model.rsquared:.3f}, N={int(model.nobs)}\")\n",
    "        return model\n",
    "\n",
    "    print(\"\\nSpec 1: Raw gap\")\n",
    "    spec1 = run_and_record('(1) Raw gap', 'log_price ~ is_female', gendered, 'None')\n",
    "\n",
    "    print(\"\\nSpec 2: + Store FE\")\n",
    "    run_and_record('(2) + Store FE', 'log_price ~ is_female + C(store)', gendered, 'Store')\n",
    "\n",
    "    # Broad category\n",
    "    cat_counts = gendered['cat_broad'].value_counts()\n",
    "    valid_broad = cat_counts[cat_counts >= 5].index\n",
    "    gen_broad = gendered[gendered['cat_broad'].isin(valid_broad)].copy()\n",
    "    print(f\"\\nSpec 3: + Broad cat FE (N cats: {len(valid_broad)})\")\n",
    "    run_and_record('(3) + Broad cat FE',\n",
    "                   'log_price ~ is_female + C(store) + C(cat_broad)',\n",
    "                   gen_broad, 'Store + Broad cat')\n",
    "\n",
    "    # Mid category\n",
    "    cat_counts = gendered['cat_mid'].value_counts()\n",
    "    valid_mid = cat_counts[cat_counts >= 5].index\n",
    "    gen_mid = gendered[gendered['cat_mid'].isin(valid_mid)].copy()\n",
    "    print(f\"\\nSpec 4: + Mid cat FE (N cats: {len(valid_mid)})\")\n",
    "    run_and_record('(4) + Mid cat FE',\n",
    "                   'log_price ~ is_female + C(store) + C(cat_mid)',\n",
    "                   gen_mid, 'Store + Mid cat')\n",
    "\n",
    "    # Fine category\n",
    "    cat_counts = gendered['cat_fine'].value_counts()\n",
    "    valid_fine = cat_counts[cat_counts >= 5].index\n",
    "    gen_fine = gendered[gendered['cat_fine'].isin(valid_fine)].copy()\n",
    "    print(f\"\\nSpec 5: + Fine cat FE (N cats: {len(valid_fine)})\")\n",
    "    if len(valid_fine) > 0 and len(gen_fine) > 50:\n",
    "        run_and_record('(5) + Fine cat FE',\n",
    "                       'log_price ~ is_female + C(store) + C(cat_fine)',\n",
    "                       gen_fine, 'Store + Fine cat')\n",
    "\n",
    "    # Description TF-IDF\n",
    "    gen_mid['desc_clean'] = gen_mid[COL_DESC].apply(clean_text_remove_gender)\n",
    "    desc_vec = TfidfVectorizer(max_features=100, min_df=5, max_df=0.9,\n",
    "                                ngram_range=(1, 2), stop_words='english')\n",
    "    X_desc = desc_vec.fit_transform(gen_mid['desc_clean'])\n",
    "\n",
    "    y6 = gen_mid['log_price'].values\n",
    "    X6_parts = [\n",
    "        gen_mid[['is_female']].values,\n",
    "        pd.get_dummies(gen_mid['store'], prefix='store', drop_first=True).values,\n",
    "        pd.get_dummies(gen_mid['cat_mid'], prefix='cat', drop_first=True).values,\n",
    "        X_desc.toarray(),\n",
    "    ]\n",
    "    X6 = sm.add_constant(np.hstack(X6_parts))\n",
    "    spec6_model = sm.OLS(y6, X6).fit(cov_type='HC1')\n",
    "\n",
    "    coef6 = spec6_model.params[1]\n",
    "    se6 = spec6_model.bse[1]\n",
    "    pval6 = spec6_model.pvalues[1]\n",
    "    results_table.append({\n",
    "        'spec': '(6) + Description', 'coef': coef6, 'se': se6, 'p': pval6,\n",
    "        'pct': (np.exp(coef6) - 1) * 100,\n",
    "        'ci_lo': coef6 - 1.96 * se6, 'ci_hi': coef6 + 1.96 * se6,\n",
    "        'pct_lo': (np.exp(coef6 - 1.96 * se6) - 1) * 100,\n",
    "        'pct_hi': (np.exp(coef6 + 1.96 * se6) - 1) * 100,\n",
    "        'r2': spec6_model.rsquared, 'n': int(spec6_model.nobs),\n",
    "        'controls': 'Store + Mid cat + Description',\n",
    "    })\n",
    "    sig6 = '***' if pval6 < 0.01 else ('**' if pval6 < 0.05 else ('*' if pval6 < 0.1 else ''))\n",
    "    print(f\"\\nSpec 6: + Description TF-IDF\")\n",
    "    print(f\"  (6) + Description: coef={coef6:+.4f} ({(np.exp(coef6)-1)*100:+.1f}%), \"\n",
    "          f\"SE={se6:.4f}, p={pval6:.4f}{sig6}, R2={spec6_model.rsquared:.3f}\")\n",
    "\n",
    "    # Female x Store interaction\n",
    "    print(f\"\\nSpec 7: Female x Store interaction\")\n",
    "    spec7 = smf.ols('log_price ~ is_female * C(store) + C(cat_mid)',\n",
    "                     data=gen_mid).fit(cov_type='HC1')\n",
    "    print(f\"  Main effect (is_female): {spec7.params['is_female']:+.4f} \"\n",
    "          f\"(p={spec7.pvalues['is_female']:.4f})\")\n",
    "    for param in spec7.params.index:\n",
    "        if 'is_female:' in param:\n",
    "            store_id = param.split('[T.')[1].rstrip(']')\n",
    "            sname = store_names.get(store_id, store_id)\n",
    "            total_effect = spec7.params['is_female'] + spec7.params[param]\n",
    "            pct_effect = (np.exp(total_effect) - 1) * 100\n",
    "            print(f\"  {sname}: total female effect = {total_effect:+.4f} ({pct_effect:+.1f}%), \"\n",
    "                  f\"interaction p={spec7.pvalues[param]:.4f}\")\n",
    "\n",
    "    # Unit price\n",
    "    print(f\"\\nSpec 8: Unit price regression\")\n",
    "    if 'unit_price_num' in gen_mid.columns:\n",
    "        gen_unit = gen_mid[gen_mid['unit_price_num'].notna() & (gen_mid['unit_price_num'] > 0)].copy()\n",
    "        gen_unit['log_unit_price'] = np.log(gen_unit['unit_price_num'])\n",
    "        if len(gen_unit) >= 50:\n",
    "            run_and_record('(8) Unit price',\n",
    "                           'log_unit_price ~ is_female + C(store) + C(cat_mid)',\n",
    "                           gen_unit, 'Store + Mid cat (unit price)')\n",
    "\n",
    "    # Three-way comparison\n",
    "    print(f\"\\nSpec 9: Three-way comparison (none = reference)\")\n",
    "    df_valid = df.copy()\n",
    "    df_valid['is_female'] = (df_valid['gender'] == 'female').astype(int)\n",
    "    df_valid['is_male'] = (df_valid['gender'] == 'male').astype(int)\n",
    "    spec9 = smf.ols('log_price ~ is_female + is_male + C(store)',\n",
    "                     data=df_valid).fit(cov_type='HC1')\n",
    "    print(f\"  is_female: {spec9.params['is_female']:+.4f} (p={spec9.pvalues['is_female']:.4f})\")\n",
    "    print(f\"  is_male:   {spec9.params['is_male']:+.4f} (p={spec9.pvalues['is_male']:.4f})\")\n",
    "\n",
    "    # ---- Quantile regression ----\n",
    "    print(f\"\\n{'='*70}\\nQUANTILE REGRESSION\\n{'='*70}\")\n",
    "    quantiles = [0.10, 0.25, 0.50, 0.75, 0.90]\n",
    "    qreg_results = []\n",
    "\n",
    "    for q in quantiles:\n",
    "        qmodel = smf.quantreg('log_price ~ is_female + C(store)', data=gendered).fit(q=q)\n",
    "        coef_q = qmodel.params['is_female']\n",
    "        se_q = qmodel.bse['is_female']\n",
    "        pval_q = qmodel.pvalues['is_female']\n",
    "        pct_q = (np.exp(coef_q) - 1) * 100\n",
    "        qreg_results.append({\n",
    "            'quantile': q, 'coef': coef_q, 'se': se_q, 'p': pval_q, 'pct': pct_q,\n",
    "            'ci_lo': coef_q - 1.96 * se_q, 'ci_hi': coef_q + 1.96 * se_q,\n",
    "        })\n",
    "        sig = '***' if pval_q < 0.01 else ('**' if pval_q < 0.05 else ('*' if pval_q < 0.1 else ''))\n",
    "        print(f\"  Q{q:.2f}: coef={coef_q:+.4f} ({pct_q:+.1f}%), p={pval_q:.4f}{sig}\")\n",
    "\n",
    "    qreg_df = pd.DataFrame(qreg_results)\n",
    "\n",
    "    print(\"\\n  With mid-category controls:\")\n",
    "    qreg_cat_results = []\n",
    "    for q in quantiles:\n",
    "        try:\n",
    "            qmodel = smf.quantreg('log_price ~ is_female + C(store) + C(cat_mid)',\n",
    "                                    data=gen_mid).fit(q=q, max_iter=5000)\n",
    "            coef_q = qmodel.params['is_female']\n",
    "            se_q = qmodel.bse['is_female']\n",
    "            pval_q = qmodel.pvalues['is_female']\n",
    "            pct_q = (np.exp(coef_q) - 1) * 100\n",
    "            qreg_cat_results.append({\n",
    "                'quantile': q, 'coef': coef_q, 'se': se_q, 'p': pval_q, 'pct': pct_q,\n",
    "                'ci_lo': coef_q - 1.96 * se_q, 'ci_hi': coef_q + 1.96 * se_q,\n",
    "            })\n",
    "            sig = '***' if pval_q < 0.01 else ('**' if pval_q < 0.05 else ('*' if pval_q < 0.1 else ''))\n",
    "            print(f\"  Q{q:.2f}: coef={coef_q:+.4f} ({pct_q:+.1f}%), p={pval_q:.4f}{sig}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Q{q:.2f}: failed ({e})\")\n",
    "    qreg_cat_df = pd.DataFrame(qreg_cat_results) if qreg_cat_results else pd.DataFrame()\n",
    "\n",
    "    # ---- Within-category analysis (bootstrap CIs) ----\n",
    "    print(f\"\\n{'='*70}\\nWITHIN-CATEGORY ANALYSIS (bootstrap CIs)\\n{'='*70}\")\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    category_gaps = []\n",
    "\n",
    "    for cat in gendered['cat_mid'].unique():\n",
    "        sub = gendered[gendered['cat_mid'] == cat]\n",
    "        fem = sub[sub['is_female'] == 1]['price_num']\n",
    "        mal = sub[sub['is_female'] == 0]['price_num']\n",
    "\n",
    "        if len(fem) >= 3 and len(mal) >= 3:\n",
    "            gap_pct = (fem.mean() / mal.mean() - 1) * 100\n",
    "            log_gap = np.log(fem).mean() - np.log(mal).mean()\n",
    "\n",
    "            boot_gaps = []\n",
    "            for _ in range(N_BOOTSTRAP):\n",
    "                f_boot = rng.choice(fem.values, size=len(fem), replace=True)\n",
    "                m_boot = rng.choice(mal.values, size=len(mal), replace=True)\n",
    "                if m_boot.mean() > 0:\n",
    "                    boot_gaps.append((f_boot.mean() / m_boot.mean() - 1) * 100)\n",
    "\n",
    "            ci_lo = np.percentile(boot_gaps, 2.5) if boot_gaps else np.nan\n",
    "            ci_hi = np.percentile(boot_gaps, 97.5) if boot_gaps else np.nan\n",
    "\n",
    "            category_gaps.append({\n",
    "                'category': cat, 'n_female': len(fem), 'n_male': len(mal),\n",
    "                'n_total': len(fem) + len(mal),\n",
    "                'mean_female': fem.mean(), 'mean_male': mal.mean(),\n",
    "                'gap_pct': gap_pct, 'log_gap': log_gap,\n",
    "                'ci_lo': ci_lo, 'ci_hi': ci_hi,\n",
    "                'significant': (ci_lo > 0 and ci_hi > 0) or (ci_lo < 0 and ci_hi < 0),\n",
    "            })\n",
    "\n",
    "    gaps_df = pd.DataFrame(category_gaps).sort_values('gap_pct', ascending=False)\n",
    "\n",
    "    if len(gaps_df) > 0:\n",
    "        print(f\"Categories with both genders (>=3 each): {len(gaps_df)}\")\n",
    "        weighted_gap = np.average(gaps_df['gap_pct'], weights=gaps_df['n_total'])\n",
    "        median_gap = gaps_df['gap_pct'].median()\n",
    "        print(f\"  Weighted mean: {weighted_gap:+.1f}%\")\n",
    "        print(f\"  Median: {median_gap:+.1f}%\")\n",
    "        gaps_df.to_csv(TEXT_DIR / 'within_category_gaps.csv', index=False)\n",
    "    else:\n",
    "        median_gap = 0\n",
    "\n",
    "    # ---- By-store analysis ----\n",
    "    print(f\"\\n{'='*70}\\nPINK TAX BY STORE\\n{'='*70}\")\n",
    "    store_results = []\n",
    "    for store_id in gendered['store'].unique():\n",
    "        sub = gendered[gendered['store'] == store_id]\n",
    "        fem = sub[sub['is_female'] == 1]\n",
    "        mal = sub[sub['is_female'] == 0]\n",
    "        sname = store_names.get(store_id, store_id)\n",
    "        if len(fem) >= 10 and len(mal) >= 10:\n",
    "            model = smf.ols('log_price ~ is_female', data=sub).fit(cov_type='HC1')\n",
    "            coef = model.params['is_female']\n",
    "            pval = model.pvalues['is_female']\n",
    "            store_results.append({\n",
    "                'store': sname, 'store_id': store_id,\n",
    "                'n_female': len(fem), 'n_male': len(mal),\n",
    "                'mean_f': fem['price_num'].mean(), 'mean_m': mal['price_num'].mean(),\n",
    "                'coef': coef, 'pct_gap': (np.exp(coef) - 1) * 100,\n",
    "                'p_value': pval, 'significant': pval < 0.05,\n",
    "            })\n",
    "\n",
    "    store_df = pd.DataFrame(store_results).sort_values('pct_gap', ascending=False)\n",
    "    if len(store_df) > 0:\n",
    "        for _, row in store_df.iterrows():\n",
    "            sig = '***' if row['p_value'] < 0.01 else ('**' if row['p_value'] < 0.05 else '')\n",
    "            print(f\"  {row['store']:<15s} F:{row['n_female']:>4.0f} M:{row['n_male']:>4.0f} \"\n",
    "                  f\"gap={row['pct_gap']:>+7.1f}% p={row['p_value']:.4f}{sig}\")\n",
    "        store_df.to_csv(TEXT_DIR / 'pink_tax_by_store.csv', index=False)\n",
    "\n",
    "    # ---- Summary table ----\n",
    "    summary_df = pd.DataFrame(results_table)\n",
    "    print(f\"\\n{'='*70}\\nREGRESSION SUMMARY\\n{'='*70}\")\n",
    "    print(f\"{'Spec':<25s} {'Coef':>8s} {'%gap':>8s} {'95% CI':>18s} {'p':>8s} {'R2':>6s} {'N':>6s}\")\n",
    "    for _, row in summary_df.iterrows():\n",
    "        sig = '***' if row['p'] < 0.01 else ('**' if row['p'] < 0.05 else ('*' if row['p'] < 0.1 else ''))\n",
    "        print(f\"{row['spec']:<25s} {row['coef']:>+7.4f} {row['pct']:>+7.1f}% \"\n",
    "              f\"[{row['pct_lo']:>+6.1f}, {row['pct_hi']:>+6.1f}] \"\n",
    "              f\"{row['p']:>7.4f}{sig:<3s} {row['r2']:>5.3f} {row['n']:>6.0f}\")\n",
    "    summary_df.to_csv(TEXT_DIR / 'regression_summary.csv', index=False)\n",
    "\n",
    "    # ---- Charts (13 interactive Plotly visualisations) ----\n",
    "    print(f\"\\n{'='*70}\\nGENERATING CHARTS (Plotly)\\n{'='*70}\")\n",
    "\n",
    "    # 1. Coefficient plot\n",
    "    specs = summary_df['spec'].values\n",
    "    coefs = summary_df['coef'].values\n",
    "    ci_los = summary_df['ci_lo'].values\n",
    "    ci_his = summary_df['ci_hi'].values\n",
    "    pct_vals = summary_df['pct'].values\n",
    "    p_vals_arr = summary_df['p'].values\n",
    "    colors_01 = [PALETTE['female'] if c > 0 else PALETTE['male'] for c in coefs]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=specs, x=coefs, orientation='h',\n",
    "        marker=dict(color=colors_01, opacity=0.75, line=dict(width=0.4, color='#333333')),\n",
    "        error_x=dict(type='data', symmetric=False,\n",
    "                     array=ci_his - coefs, arrayminus=coefs - ci_los,\n",
    "                     color='#333333', thickness=1.0, width=3),\n",
    "        hovertemplate='%{y}<br>Coef: %{x:.4f}<extra></extra>',\n",
    "    ))\n",
    "    for i in range(len(specs)):\n",
    "        fw = 'bold' if p_vals_arr[i] < 0.05 else 'normal'\n",
    "        fig.add_annotation(x=ci_his[i] + 0.01, y=specs[i],\n",
    "                           text=f'{pct_vals[i]:+.1f}%', showarrow=False,\n",
    "                           xanchor='left', font=dict(size=10, weight=fw))\n",
    "    fig.add_vline(x=0, line=dict(color='#1a1a2e', width=0.8))\n",
    "    fig.update_layout(**base_layout(height=STYLE['chart_height'],\n",
    "                                     margin=STYLE['margin_bar']),\n",
    "                       xaxis=styled_axis('Coefficient on female indicator (log price)'),\n",
    "                       yaxis=styled_axis('', autorange='reversed'))\n",
    "    save_html(fig, CHART_REG_DIR / '01_coefficient_plot.html')\n",
    "\n",
    "    # 2. Quantile regression\n",
    "    fig = make_subplots(rows=1, cols=2, horizontal_spacing=0.08,\n",
    "                        subplot_titles=['Baseline', 'With category FE'])\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=qreg_df['quantile'], y=qreg_df['ci_hi'],\n",
    "        mode='lines', line=dict(width=0), showlegend=False), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=qreg_df['quantile'], y=qreg_df['ci_lo'],\n",
    "        mode='lines', line=dict(width=0), fill='tonexty',\n",
    "        fillcolor='rgba(196,78,82,0.15)', showlegend=False), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=qreg_df['quantile'], y=qreg_df['coef'],\n",
    "        mode='lines+markers', line=dict(color=PALETTE['female'], width=2),\n",
    "        marker=dict(size=6), name='Baseline',\n",
    "        hovertemplate='Q%{x:.2f}: %{y:.4f}<extra></extra>'), row=1, col=1)\n",
    "    fig.add_hline(y=0, line=dict(color='black', width=0.8, dash='dash'), row=1, col=1)\n",
    "    if len(qreg_cat_df) > 0:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=qreg_cat_df['quantile'], y=qreg_cat_df['ci_hi'],\n",
    "            mode='lines', line=dict(width=0), showlegend=False), row=1, col=2)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=qreg_cat_df['quantile'], y=qreg_cat_df['ci_lo'],\n",
    "            mode='lines', line=dict(width=0), fill='tonexty',\n",
    "            fillcolor='rgba(196,78,82,0.15)', showlegend=False), row=1, col=2)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=qreg_cat_df['quantile'], y=qreg_cat_df['coef'],\n",
    "            mode='lines+markers', line=dict(color=PALETTE['female'], width=2),\n",
    "            marker=dict(size=6), name='With FE',\n",
    "            hovertemplate='Q%{x:.2f}: %{y:.4f}<extra></extra>'), row=1, col=2)\n",
    "        fig.add_hline(y=0, line=dict(color='black', width=0.8, dash='dash'), row=1, col=2)\n",
    "    fig.update_layout(**base_layout(height=STYLE['chart_height'], margin=dict(l=60, r=40, t=40, b=50)))\n",
    "    fig.update_xaxes(**styled_axis('Quantile'))\n",
    "    fig.update_yaxes(**styled_axis('Coefficient on female (log price)'))\n",
    "    save_html(fig, CHART_REG_DIR / '02_quantile_regression.html')\n",
    "\n",
    "    # 3. Within-category gaps\n",
    "    if len(gaps_df) > 0:\n",
    "        gaps_sorted = gaps_df.sort_values('gap_pct')\n",
    "        labels_03 = [f\"{r['category'][:42]} (F:{r['n_female']:.0f}, M:{r['n_male']:.0f})\"\n",
    "                     for _, r in gaps_sorted.iterrows()]\n",
    "        colors_03 = [PALETTE['female'] if g > 0 else PALETTE['male'] for g in gaps_sorted['gap_pct']]\n",
    "        border_03 = ['black' if s else '#cccccc' for s in gaps_sorted['significant']]\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=labels_03, x=gaps_sorted['gap_pct'].values, orientation='h',\n",
    "            marker=dict(color=colors_03, opacity=0.6,\n",
    "                        line=dict(width=[1.0 if s else 0.3 for s in gaps_sorted['significant']],\n",
    "                                  color=border_03)),\n",
    "            error_x=dict(type='data', symmetric=False,\n",
    "                         array=gaps_sorted['ci_hi'].values - gaps_sorted['gap_pct'].values,\n",
    "                         arrayminus=gaps_sorted['gap_pct'].values - gaps_sorted['ci_lo'].values,\n",
    "                         color='black', thickness=0.8, width=3),\n",
    "            hovertemplate='%{y}<br>Gap: %{x:+.1f}%<extra></extra>',\n",
    "        ))\n",
    "        fig.add_vline(x=0, line=dict(color='black', width=1))\n",
    "        h = max(STYLE['chart_height_tall'], len(gaps_sorted) * 28)\n",
    "        fig.update_layout(**base_layout(height=h, margin=dict(l=350, r=60, t=20, b=50)),\n",
    "                           xaxis=styled_axis('Female price premium (%)'),\n",
    "                           yaxis=styled_axis(''))\n",
    "        save_html(fig, CHART_REG_DIR / '03_within_category_gaps.html')\n",
    "\n",
    "    # 4. Price distributions (4 panels)\n",
    "    fig = make_subplots(rows=2, cols=2, horizontal_spacing=0.08, vertical_spacing=0.1,\n",
    "                        subplot_titles=['Price density', 'Log price density',\n",
    "                                        'Price box plot', 'Price CDF'])\n",
    "    for gender, color in [('female', PALETTE['female']), ('male', PALETTE['male'])]:\n",
    "        sub = gendered[gendered['gender'] == gender]\n",
    "        fig.add_trace(go.Histogram(\n",
    "            x=sub['price_num'], nbinsx=50, histnorm='probability density',\n",
    "            marker=dict(color=color, opacity=0.5),\n",
    "            name=f'{gender.title()} (n={len(sub):,})', legendgroup=gender,\n",
    "            hovertemplate='Price: %{x:.1f}<br>Density: %{y:.4f}<extra></extra>',\n",
    "        ), row=1, col=1)\n",
    "        fig.add_trace(go.Histogram(\n",
    "            x=sub['log_price'], nbinsx=50, histnorm='probability density',\n",
    "            marker=dict(color=color, opacity=0.5),\n",
    "            name=f'{gender.title()}', legendgroup=gender, showlegend=False,\n",
    "        ), row=1, col=2)\n",
    "    for gender, color in [('female', PALETTE['female']), ('male', PALETTE['male'])]:\n",
    "        sub = gendered[gendered['gender'] == gender]\n",
    "        fig.add_trace(go.Box(\n",
    "            y=sub['price_num'], name=gender.title(), marker_color=color,\n",
    "            boxmean=True, showlegend=False,\n",
    "            hovertemplate='%{y:.1f}<extra></extra>',\n",
    "        ), row=2, col=1)\n",
    "    for gender, color in [('female', PALETTE['female']), ('male', PALETTE['male'])]:\n",
    "        sub = gendered[gendered['gender'] == gender]['price_num'].sort_values()\n",
    "        cdf = np.arange(1, len(sub) + 1) / len(sub)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=sub, y=cdf, mode='lines', line=dict(color=color, width=1.5),\n",
    "            name=gender.title(), showlegend=False,\n",
    "            hovertemplate='Price: %{x:.1f}<br>CDF: %{y:.2f}<extra></extra>',\n",
    "        ), row=2, col=2)\n",
    "    q95 = gendered['price_num'].quantile(0.95)\n",
    "    fig.update_xaxes(range=[0, q95], row=1, col=1)\n",
    "    fig.update_xaxes(range=[0, q95], row=2, col=2)\n",
    "    fig.update_layout(**base_layout(height=700, margin=dict(l=60, r=40, t=40, b=50)),\n",
    "                       barmode='overlay')\n",
    "    save_html(fig, CHART_REG_DIR / '04_price_distributions.html')\n",
    "\n",
    "    # 5. By store\n",
    "    if len(store_df) > 0:\n",
    "        fig = make_subplots(rows=1, cols=2, horizontal_spacing=0.08,\n",
    "                            subplot_titles=['Price premium by store', 'Mean price by store'])\n",
    "        store_sorted = store_df.sort_values('pct_gap')\n",
    "        colors_05 = [PALETTE['female'] if g > 0 else PALETTE['male'] for g in store_sorted['pct_gap']]\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=store_sorted['store'].values, x=store_sorted['pct_gap'].values, orientation='h',\n",
    "            marker=dict(color=colors_05, opacity=0.7,\n",
    "                        line=dict(width=[2 if s else 0.5 for s in store_sorted['significant']],\n",
    "                                  color='black')),\n",
    "            hovertemplate='%{y}<br>Gap: %{x:+.1f}%<extra></extra>', showlegend=False,\n",
    "        ), row=1, col=1)\n",
    "        fig.add_vline(x=0, line=dict(color='black', width=1), row=1, col=1)\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=store_df['store'].values, y=store_df['mean_f'].values,\n",
    "            marker=dict(color=PALETTE['female'], opacity=0.7), name='Female',\n",
    "        ), row=1, col=2)\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=store_df['store'].values, y=store_df['mean_m'].values,\n",
    "            marker=dict(color=PALETTE['male'], opacity=0.7), name='Male',\n",
    "        ), row=1, col=2)\n",
    "        fig.update_layout(**base_layout(height=STYLE['chart_height'],\n",
    "                                         margin=dict(l=160, r=40, t=40, b=50)),\n",
    "                           barmode='group')\n",
    "        save_html(fig, CHART_REG_DIR / '05_by_store.html')\n",
    "\n",
    "    # 6. Scatter by category\n",
    "    if len(gaps_df) > 0:\n",
    "        colors_06 = [PALETTE['female'] if g > 0 else PALETTE['male'] for g in gaps_df['gap_pct']]\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=gaps_df['mean_male'], y=gaps_df['mean_female'],\n",
    "            mode='markers',\n",
    "            marker=dict(size=np.sqrt(gaps_df['n_total'].values) * 2,\n",
    "                        color=colors_06, opacity=0.6,\n",
    "                        line=dict(width=0.5, color='black')),\n",
    "            text=gaps_df['category'].str[:30],\n",
    "            hovertemplate='%{text}<br>Male: %{x:.2f}<br>Female: %{y:.2f}<extra></extra>',\n",
    "        ))\n",
    "        lim_max = max(gaps_df['mean_male'].max(), gaps_df['mean_female'].max()) * 1.1\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[0, lim_max], y=[0, lim_max], mode='lines',\n",
    "            line=dict(color='black', width=0.8, dash='dash'),\n",
    "            name='Equal price', hoverinfo='skip'))\n",
    "        for _, row in gaps_df.nlargest(3, 'gap_pct').iterrows():\n",
    "            fig.add_annotation(x=row['mean_male'], y=row['mean_female'],\n",
    "                               text=row['category'][:30], showarrow=True,\n",
    "                               arrowhead=0, ax=20, ay=-20,\n",
    "                               font=dict(size=9, color='#555'))\n",
    "        fig.update_layout(**base_layout(height=550, margin=dict(l=60, r=40, t=20, b=60)),\n",
    "                           xaxis=styled_axis('Mean male price'),\n",
    "                           yaxis=styled_axis('Mean female price'))\n",
    "        save_html(fig, CHART_REG_DIR / '06_scatter_by_category.html')\n",
    "\n",
    "    # 7. Three-way comparison\n",
    "    fig = make_subplots(rows=1, cols=2, horizontal_spacing=0.08,\n",
    "                        subplot_titles=['Log price density', 'Price box plot'])\n",
    "    for gender, color in [('female', PALETTE['female']), ('male', PALETTE['male']),\n",
    "                           ('none', PALETTE['none'])]:\n",
    "        sub = df[df['gender'] == gender]\n",
    "        fig.add_trace(go.Histogram(\n",
    "            x=sub['log_price'], nbinsx=60, histnorm='probability density',\n",
    "            marker=dict(color=color, opacity=0.4),\n",
    "            name=f'{gender.title()} (n={len(sub):,})', legendgroup=gender,\n",
    "        ), row=1, col=1)\n",
    "    for gender, color in [('female', PALETTE['female']), ('male', PALETTE['male']),\n",
    "                           ('none', PALETTE['none'])]:\n",
    "        sub = df[df['gender'] == gender]\n",
    "        fig.add_trace(go.Box(\n",
    "            y=sub['price_num'], name=gender.title(), marker_color=color,\n",
    "            showlegend=False, boxmean=True,\n",
    "        ), row=1, col=2)\n",
    "    fig.update_layout(**base_layout(height=STYLE['chart_height'],\n",
    "                                     margin=dict(l=60, r=40, t=40, b=50)),\n",
    "                       barmode='overlay')\n",
    "    save_html(fig, CHART_REG_DIR / '07_three_way_comparison.html')\n",
    "\n",
    "    # 8. Category composition\n",
    "    fig = make_subplots(rows=1, cols=2, horizontal_spacing=0.08,\n",
    "                        subplot_titles=['Female', 'Male'])\n",
    "    for col_idx, gender in enumerate(['female', 'male'], 1):\n",
    "        sub = gendered[gendered['gender'] == gender]\n",
    "        top_cats = sub['cat_mid'].value_counts().head(12)\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=[c[:40] for c in top_cats.index], x=top_cats.values, orientation='h',\n",
    "            marker=dict(color=PALETTE[gender], opacity=0.7,\n",
    "                        line=dict(width=0.3, color='black')),\n",
    "            hovertemplate='%{y}<br>Count: %{x:,}<extra></extra>',\n",
    "            showlegend=False,\n",
    "        ), row=1, col=col_idx)\n",
    "    fig.update_yaxes(autorange='reversed')\n",
    "    fig.update_layout(**base_layout(height=STYLE['chart_height'],\n",
    "                                     margin=dict(l=280, r=40, t=40, b=50)))\n",
    "    fig.update_xaxes(**styled_axis('Number of products'))\n",
    "    save_html(fig, CHART_REG_DIR / '08_category_composition.html')\n",
    "\n",
    "    # 9. Gap distribution\n",
    "    if len(gaps_df) > 0:\n",
    "        med_gap = gaps_df['gap_pct'].median()\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Histogram(\n",
    "            x=gaps_df['gap_pct'], nbinsx=max(5, len(gaps_df) // 2),\n",
    "            marker=dict(color=PALETTE['female'], opacity=0.6,\n",
    "                        line=dict(width=0.5, color='black')),\n",
    "            hovertemplate='Gap: %{x:.1f}%<br>Count: %{y}<extra></extra>',\n",
    "        ))\n",
    "        fig.add_vline(x=0, line=dict(color='black', width=1.5))\n",
    "        fig.add_vline(x=med_gap, line=dict(color=PALETTE['female'], width=1.5, dash='dash'),\n",
    "                      annotation_text=f'Median: {med_gap:+.1f}%',\n",
    "                      annotation_position='top right')\n",
    "        fig.update_layout(**base_layout(height=STYLE['chart_height_small']),\n",
    "                           xaxis=styled_axis('Female price premium (%)'),\n",
    "                           yaxis=styled_axis('Number of categories'))\n",
    "        save_html(fig, CHART_REG_DIR / '09_gap_distribution.html')\n",
    "\n",
    "    # 10. R2 progression\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=summary_df['spec'].values, x=summary_df['r2'].values, orientation='h',\n",
    "        marker=dict(color='#555555', opacity=0.7, line=dict(width=0.5, color='black')),\n",
    "        hovertemplate='%{y}<br>R\\u00b2: %{x:.4f}<extra></extra>',\n",
    "    ))\n",
    "    for i, r2 in enumerate(summary_df['r2']):\n",
    "        fig.add_annotation(x=r2 + 0.01, y=summary_df['spec'].values[i],\n",
    "                           text=f'{r2:.3f}', showarrow=False,\n",
    "                           xanchor='left', font=dict(size=10))\n",
    "    fig.update_layout(**base_layout(height=STYLE['chart_height_small'],\n",
    "                                     margin=STYLE['margin_bar']),\n",
    "                       xaxis=styled_axis('R\\u00b2'),\n",
    "                       yaxis=styled_axis('', autorange='reversed'))\n",
    "    save_html(fig, CHART_REG_DIR / '10_r2_progression.html')\n",
    "\n",
    "    # 11. Heatmap: category x store\n",
    "    heatmap_data = []\n",
    "    for cat in gendered['cat_mid'].unique():\n",
    "        for store_id in gendered['store'].unique():\n",
    "            sub = gendered[(gendered['cat_mid'] == cat) & (gendered['store'] == store_id)]\n",
    "            fem = sub[sub['is_female'] == 1]\n",
    "            mal = sub[sub['is_female'] == 0]\n",
    "            if len(fem) >= 2 and len(mal) >= 2:\n",
    "                gap = (fem['price_num'].mean() / mal['price_num'].mean() - 1) * 100\n",
    "                heatmap_data.append({\n",
    "                    'category': cat[:35],\n",
    "                    'store': store_names.get(store_id, store_id),\n",
    "                    'gap': gap, 'n': len(fem) + len(mal),\n",
    "                })\n",
    "\n",
    "    if heatmap_data:\n",
    "        heat_df = pd.DataFrame(heatmap_data)\n",
    "        pivot = heat_df.pivot_table(values='gap', index='category', columns='store', aggfunc='mean')\n",
    "        pivot = pivot.dropna(thresh=2)\n",
    "        if len(pivot) > 0:\n",
    "            finite_vals = pivot.values[np.isfinite(pivot.values)]\n",
    "            max_abs = max(abs(finite_vals.min()), abs(finite_vals.max()))\n",
    "            # Build text array handling NaN\n",
    "            text_arr = []\n",
    "            for row in pivot.values:\n",
    "                text_row = []\n",
    "                for v in row:\n",
    "                    if np.isfinite(v):\n",
    "                        text_row.append(f'{v:.0f}')\n",
    "                    else:\n",
    "                        text_row.append('')\n",
    "                text_arr.append(text_row)\n",
    "            fig = go.Figure(data=go.Heatmap(\n",
    "                z=pivot.values, x=pivot.columns.tolist(), y=pivot.index.tolist(),\n",
    "                colorscale='RdBu_r', zmid=0, zmin=-max_abs, zmax=max_abs,\n",
    "                text=text_arr,\n",
    "                texttemplate='%{text}', textfont=dict(size=10),\n",
    "                colorbar=dict(title='F vs M gap (%)', **STYLE['colorbar']),\n",
    "                hovertemplate='%{y}<br>%{x}<br>Gap: %{z:.1f}%<extra></extra>',\n",
    "            ))\n",
    "            h = max(STYLE['chart_height'], len(pivot) * 28)\n",
    "            fig.update_layout(**base_layout(height=h, margin=dict(l=250, r=80, t=20, b=50)),\n",
    "                               yaxis=styled_axis(''))\n",
    "            save_html(fig, CHART_REG_DIR / '11_heatmap_category_store.html')\n",
    "\n",
    "    # 12. Summary dashboard (6 panels)\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=3, horizontal_spacing=0.08, vertical_spacing=0.12,\n",
    "        subplot_titles=['Key Finding', '% Gap by Specification', 'R\\u00b2 by Specification',\n",
    "                        'Log Price Density', 'Quantile Regression', 'Store Gaps'],\n",
    "        specs=[[{'type': 'xy'}, {'type': 'xy'}, {'type': 'xy'}],\n",
    "               [{'type': 'xy'}, {'type': 'xy'}, {'type': 'xy'}]],\n",
    "    )\n",
    "    raw_gap = (np.exp(spec1.params['is_female']) - 1) * 100\n",
    "    ctrl_gap = summary_df.iloc[-1]['pct']\n",
    "    fig.add_annotation(x=0.5, y=0.8, xref='x domain', yref='y domain',\n",
    "                       text=f'Raw gap: {raw_gap:+.1f}%', showarrow=False,\n",
    "                       font=dict(size=20, color=PALETTE['male'], weight='bold'),\n",
    "                       row=1, col=1)\n",
    "    fig.add_annotation(x=0.5, y=0.45, xref='x domain', yref='y domain',\n",
    "                       text='(female products cheaper)', showarrow=False,\n",
    "                       font=dict(size=11, color='gray'), row=1, col=1)\n",
    "    fig.add_annotation(x=0.5, y=0.15, xref='x domain', yref='y domain',\n",
    "                       text=f'After controls: {ctrl_gap:+.1f}% (n.s.)', showarrow=False,\n",
    "                       font=dict(size=13, color='gray'), row=1, col=1)\n",
    "    fig.update_xaxes(visible=False, row=1, col=1)\n",
    "    fig.update_yaxes(visible=False, row=1, col=1)\n",
    "\n",
    "    colors_12b = [PALETTE['female'] if c > 0 else PALETTE['male'] for c in summary_df['coef']]\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=[s[:18] for s in summary_df['spec']], x=summary_df['pct'], orientation='h',\n",
    "        marker=dict(color=colors_12b, opacity=0.7), showlegend=False,\n",
    "    ), row=1, col=2)\n",
    "    fig.add_vline(x=0, line=dict(color='black', width=1), row=1, col=2)\n",
    "    fig.update_yaxes(autorange='reversed', row=1, col=2)\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=[s[:18] for s in summary_df['spec']], x=summary_df['r2'], orientation='h',\n",
    "        marker=dict(color='#666', opacity=0.7), showlegend=False,\n",
    "    ), row=1, col=3)\n",
    "    fig.update_yaxes(autorange='reversed', row=1, col=3)\n",
    "\n",
    "    for gender, color in [('female', PALETTE['female']), ('male', PALETTE['male'])]:\n",
    "        sub = gendered[gendered['gender'] == gender]\n",
    "        fig.add_trace(go.Histogram(\n",
    "            x=sub['log_price'], nbinsx=40, histnorm='probability density',\n",
    "            marker=dict(color=color, opacity=0.5),\n",
    "            name=gender.title(), showlegend=True, legendgroup=gender,\n",
    "        ), row=2, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=qreg_df['quantile'], y=qreg_df['ci_hi'],\n",
    "        mode='lines', line=dict(width=0), showlegend=False), row=2, col=2)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=qreg_df['quantile'], y=qreg_df['ci_lo'],\n",
    "        mode='lines', line=dict(width=0), fill='tonexty',\n",
    "        fillcolor='rgba(196,78,82,0.15)', showlegend=False), row=2, col=2)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=qreg_df['quantile'], y=qreg_df['coef'],\n",
    "        mode='lines+markers', line=dict(color=PALETTE['female'], width=2),\n",
    "        marker=dict(size=5), showlegend=False), row=2, col=2)\n",
    "    fig.add_hline(y=0, line=dict(color='black', width=0.8, dash='dash'), row=2, col=2)\n",
    "\n",
    "    if len(store_df) > 0:\n",
    "        colors_12f = [PALETTE['female'] if g > 0 else PALETTE['male'] for g in store_df['pct_gap']]\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=store_df['store'].values, x=store_df['pct_gap'].values, orientation='h',\n",
    "            marker=dict(color=colors_12f, opacity=0.7), showlegend=False,\n",
    "        ), row=2, col=3)\n",
    "        fig.add_vline(x=0, line=dict(color='black', width=1), row=2, col=3)\n",
    "    fig.update_layout(**base_layout(height=750, margin=dict(l=140, r=40, t=40, b=50)),\n",
    "                       barmode='overlay')\n",
    "    save_html(fig, CHART_REG_DIR / '12_summary_dashboard.html')\n",
    "\n",
    "    # 13. Waterfall decomposition chart\n",
    "    if len(summary_df) >= 4:\n",
    "        spec_labels = summary_df['spec'].values\n",
    "        pct_gaps = summary_df['pct'].values\n",
    "        p_vals_w = summary_df['p'].values\n",
    "        n = len(spec_labels)\n",
    "        deltas = np.zeros(n)\n",
    "        starts = np.zeros(n)\n",
    "        deltas[0] = pct_gaps[0]\n",
    "        starts[0] = 0\n",
    "        for i in range(1, n):\n",
    "            deltas[i] = pct_gaps[i] - pct_gaps[i - 1]\n",
    "            starts[i] = pct_gaps[i - 1]\n",
    "\n",
    "        bar_colors_w = []\n",
    "        for i in range(n):\n",
    "            if i == 0:\n",
    "                bar_colors_w.append(PALETTE['male'] if pct_gaps[0] < 0 else PALETTE['female'])\n",
    "            elif i == n - 1:\n",
    "                bar_colors_w.append('#555555')\n",
    "            else:\n",
    "                bar_colors_w.append(PALETTE['female'] if deltas[i] > 0 else PALETTE['male'])\n",
    "\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=spec_labels[:-1], x=deltas[:-1], orientation='h',\n",
    "            base=starts[:-1],\n",
    "            marker=dict(color=bar_colors_w[:-1], opacity=0.75,\n",
    "                        line=dict(width=0.4, color='#333333')),\n",
    "            hovertemplate='%{y}<br>Change: %{x:+.1f}%<extra></extra>',\n",
    "            showlegend=False,\n",
    "        ))\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=[spec_labels[-1]], x=[pct_gaps[-1]], orientation='h',\n",
    "            base=[0],\n",
    "            marker=dict(color=bar_colors_w[-1], opacity=0.75,\n",
    "                        line=dict(width=0.4, color='#333333')),\n",
    "            hovertemplate='%{y}<br>Total: %{x:+.1f}%<extra></extra>',\n",
    "            showlegend=False,\n",
    "        ))\n",
    "        for i in range(n):\n",
    "            sig_mark = '' if p_vals_w[i] < 0.05 else ' (n.s.)'\n",
    "            x_pos = pct_gaps[i]\n",
    "            fig.add_annotation(x=x_pos + (0.8 if x_pos >= 0 else -0.8),\n",
    "                               y=spec_labels[i],\n",
    "                               text=f'{pct_gaps[i]:+.1f}%{sig_mark}',\n",
    "                               showarrow=False,\n",
    "                               xanchor='left' if x_pos >= 0 else 'right',\n",
    "                               font=dict(size=10, weight=600, color='#333333'))\n",
    "        fig.add_vline(x=0, line=dict(color='#1a1a2e', width=0.8))\n",
    "        fig.update_layout(**base_layout(height=STYLE['chart_height'],\n",
    "                                         margin=STYLE['margin_bar']),\n",
    "                           xaxis=styled_axis('Female price gap (%)'),\n",
    "                           yaxis=styled_axis('', autorange='reversed'))\n",
    "        save_html(fig, CHART_REG_DIR / '13_waterfall_decomposition.html')\n",
    "\n",
    "    # Save full summary JSON\n",
    "    full_summary = {\n",
    "        'raw_gap_pct': float((np.exp(spec1.params['is_female']) - 1) * 100),\n",
    "        'raw_gap_p': float(spec1.pvalues['is_female']),\n",
    "        'controlled_gap_pct': float(summary_df.iloc[-1]['pct']),\n",
    "        'controlled_gap_p': float(summary_df.iloc[-1]['p']),\n",
    "        'within_category_median_gap': float(median_gap) if len(gaps_df) > 0 else None,\n",
    "        'n_gendered_products': int(len(gendered)),\n",
    "        'n_female': int(gendered['is_female'].sum()),\n",
    "        'n_male': int((1 - gendered['is_female']).sum()),\n",
    "        'quantile_results': qreg_df.to_dict('records'),\n",
    "        'store_results': store_df.to_dict('records') if len(store_df) > 0 else [],\n",
    "    }\n",
    "    with open(TEXT_DIR / 'full_summary.json', 'w') as f:\n",
    "        json.dump(full_summary, f, indent=2, default=str)\n",
    "\n",
    "    print(f\"\\nCharts saved to {CHART_REG_DIR}, tables in {TEXT_DIR}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STAGE 4: COLOR VISUALISATIONS\n",
    "# ============================================================================\n",
    "\n",
    "def run_color_charts():\n",
    "    \"\"\"Stage 4: color distribution, importance, and comparison charts (Plotly).\"\"\"\n",
    "    CHART_VAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    IMPORTANCE_PATH = TEXT_DIR / 'feature_importance.csv'\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"STAGE 4: COLOR VISUALISATIONS (Plotly)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    color_df = pd.read_csv(COLOR_CACHE_PATH)\n",
    "    print(f\"Color cache: {len(color_df):,} products\")\n",
    "\n",
    "    has_importance = IMPORTANCE_PATH.exists()\n",
    "    if has_importance:\n",
    "        importance_df = pd.read_csv(IMPORTANCE_PATH)\n",
    "        print(f\"Feature importance: {len(importance_df)} features\")\n",
    "    else:\n",
    "        importance_df = None\n",
    "        print(\"No feature_importance.csv found -- will skip LASSO charts\")\n",
    "\n",
    "    # Build frequency table by gender\n",
    "    color_gender = color_df[['label_extracted', 'color1_name']].copy()\n",
    "    color_gender = color_gender[color_gender['label_extracted'].isin(['female', 'male', 'none'])]\n",
    "    color_gender = color_gender.rename(columns={'color1_name': 'color'})\n",
    "\n",
    "    freq = color_gender.groupby(['label_extracted', 'color']).size().unstack(fill_value=0)\n",
    "    freq_pct = freq.div(freq.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    mask = (freq_pct > 1).any(axis=0)\n",
    "    freq_pct_filtered = freq_pct.loc[:, mask].copy()\n",
    "    col_order = freq_pct_filtered.sum().sort_values(ascending=False).index\n",
    "    freq_pct_filtered = freq_pct_filtered[col_order]\n",
    "    print(f\"Colors with >1% share: {len(col_order)}\")\n",
    "\n",
    "    gender_labels = {'female': 'Female Products', 'male': 'Male Products', 'none': 'Neutral Products'}\n",
    "    gender_accent = {'female': '#c44e52', 'male': '#4c72b0', 'none': '#777777'}\n",
    "\n",
    "    # ---- Chart 1: Color distribution by gender ----\n",
    "    print(\"\\nGenerating color distribution chart...\")\n",
    "    fig = make_subplots(rows=1, cols=3, horizontal_spacing=0.06,\n",
    "                        subplot_titles=[gender_labels.get(g, g) for g in ['female', 'male', 'none']])\n",
    "\n",
    "    for col_idx, gender in enumerate(['female', 'male', 'none'], 1):\n",
    "        if gender not in freq_pct_filtered.index:\n",
    "            continue\n",
    "        row = freq_pct_filtered.loc[gender].sort_values(ascending=True).tail(15)\n",
    "        color_names = row.index.tolist()\n",
    "        values = row.values\n",
    "        n_total = int(freq.loc[gender].sum()) if gender in freq.index else 0\n",
    "\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=[c.replace('_', ' ').title() for c in color_names],\n",
    "            x=values, orientation='h',\n",
    "            marker=dict(color=[rgb_hex(c) for c in color_names],\n",
    "                        line=dict(width=0.8,\n",
    "                                  color=[edge_color_for(c) if edge_color_for(c) != 'none'\n",
    "                                         else 'rgba(0,0,0,0)' for c in color_names])),\n",
    "            text=[f'{v:.1f}%' for v in values],\n",
    "            textposition='outside', textfont=dict(size=9),\n",
    "            hovertemplate='%{y}: %{x:.1f}%<extra></extra>',\n",
    "            showlegend=False,\n",
    "        ), row=1, col=col_idx)\n",
    "        fig.add_annotation(x=0.97, y=0.03, xref=f'x{\"\" if col_idx == 1 else col_idx} domain', yref=f'y{\"\" if col_idx == 1 else col_idx} domain',\n",
    "                           text=f'n = {n_total:,}', showarrow=False,\n",
    "                           font=dict(size=9, color='#999999'), xanchor='right', yanchor='bottom')\n",
    "\n",
    "    fig.update_layout(**base_layout(height=550, margin=dict(l=120, r=60, t=40, b=50)))\n",
    "    fig.update_xaxes(**styled_axis('Share of products (%)'))\n",
    "    save_html(fig, CHART_VAL_DIR / 'color_distribution_by_gender.html')\n",
    "\n",
    "    # ---- Chart 2: Color importance (LASSO coefficients) ----\n",
    "    if has_importance:\n",
    "        print(\"\\nGenerating color importance chart...\")\n",
    "        color_feats = importance_df[importance_df['feature'].str.startswith('feat_color1_')].copy()\n",
    "        color_feats['color_name'] = color_feats['feature'].str.replace('feat_color1_', '', regex=False)\n",
    "        color_feats['max_coef'] = color_feats[['coef_female', 'coef_male', 'coef_none']].abs().max(axis=1)\n",
    "        color_feats = color_feats[color_feats['max_coef'] > 0.01].sort_values('max_coef', ascending=False)\n",
    "\n",
    "        if len(color_feats) == 0:\n",
    "            for slot in ['color2_', 'color3_']:\n",
    "                extra = importance_df[importance_df['feature'].str.startswith(f'feat_{slot}')].copy()\n",
    "                extra['color_name'] = extra['feature'].str.replace(f'feat_{slot}', '', regex=False)\n",
    "                extra['max_coef'] = extra[['coef_female', 'coef_male', 'coef_none']].abs().max(axis=1)\n",
    "                color_feats = pd.concat([color_feats, extra[extra['max_coef'] > 0.01]])\n",
    "\n",
    "        if len(color_feats) > 0:\n",
    "            agg = color_feats.groupby('color_name')[['coef_female', 'coef_male', 'coef_none']].sum()\n",
    "            agg['max_abs'] = agg.abs().max(axis=1)\n",
    "            agg = agg.sort_values('max_abs', ascending=False).head(18)\n",
    "\n",
    "            coef_cols = [('coef_female', 'Female Predictors', '#c44e52'),\n",
    "                         ('coef_male', 'Male Predictors', '#4c72b0'),\n",
    "                         ('coef_none', 'Neutral Predictors', '#777777')]\n",
    "\n",
    "            fig = make_subplots(rows=1, cols=3, shared_yaxes=True, horizontal_spacing=0.04,\n",
    "                                subplot_titles=[lbl for _, lbl, _ in coef_cols])\n",
    "\n",
    "            for col_idx, (col, label, accent) in enumerate(coef_cols, 1):\n",
    "                sorted_data = agg[col].sort_values()\n",
    "                color_names = sorted_data.index.tolist()\n",
    "                values = sorted_data.values\n",
    "                fig.add_trace(go.Bar(\n",
    "                    y=[c.replace('_', ' ').title() for c in color_names],\n",
    "                    x=values, orientation='h',\n",
    "                    marker=dict(color=[rgb_hex(c) for c in color_names],\n",
    "                                line=dict(width=0.8,\n",
    "                                          color=[edge_color_for(c) if edge_color_for(c) != 'none'\n",
    "                                                 else 'rgba(0,0,0,0)' for c in color_names])),\n",
    "                    text=[f'{v:+.2f}' if abs(v) > 0.02 else '' for v in values],\n",
    "                    textposition='outside', textfont=dict(size=8, color='#444444'),\n",
    "                    hovertemplate='%{y}: %{x:+.3f}<extra></extra>',\n",
    "                    showlegend=False,\n",
    "                ), row=1, col=col_idx)\n",
    "                fig.add_vline(x=0, line=dict(color='#1a1a1a', width=0.8), row=1, col=col_idx)\n",
    "\n",
    "            fig.update_layout(**base_layout(height=600, margin=dict(l=130, r=60, t=40, b=50)))\n",
    "            fig.update_xaxes(**styled_axis('LASSO coefficient'))\n",
    "            save_html(fig, CHART_VAL_DIR / 'color_importance.html')\n",
    "\n",
    "    # ---- Chart 3: Color importance heatmap ----\n",
    "    if has_importance:\n",
    "        print(\"\\nGenerating color importance heatmap...\")\n",
    "        all_color = []\n",
    "        for slot in range(1, 4):\n",
    "            prefix = f'feat_color{slot}_'\n",
    "            sub = importance_df[importance_df['feature'].str.startswith(prefix)].copy()\n",
    "            sub['color_name'] = sub['feature'].str.replace(prefix, '', regex=False)\n",
    "            sub['slot'] = slot\n",
    "            all_color.append(sub)\n",
    "\n",
    "        all_color_df = pd.concat(all_color)\n",
    "        hm_data = all_color_df.groupby('color_name')[\n",
    "            ['coef_female', 'coef_male', 'coef_none']].sum()\n",
    "        hm_data.columns = ['Female', 'Male', 'Neutral']\n",
    "        hm_data['max_abs'] = hm_data.abs().max(axis=1)\n",
    "        hm_data = hm_data[hm_data['max_abs'] > 0.01].drop(columns='max_abs')\n",
    "        hm_data = hm_data.sort_values('Female', ascending=True)\n",
    "\n",
    "        if len(hm_data) > 0:\n",
    "            max_val = max(abs(hm_data.values.min()), abs(hm_data.values.max()))\n",
    "            fig = go.Figure(data=go.Heatmap(\n",
    "                z=hm_data.values,\n",
    "                x=hm_data.columns.tolist(),\n",
    "                y=[c.replace('_', ' ').title() for c in hm_data.index.tolist()],\n",
    "                colorscale='RdBu_r', zmid=0, zmin=-max_val, zmax=max_val,\n",
    "                text=[[f'{v:+.2f}' if abs(v) > 0.01 else '' for v in row] for row in hm_data.values],\n",
    "                texttemplate='%{text}', textfont=dict(size=9),\n",
    "                colorbar=dict(title='L1 coefficient', **STYLE['colorbar']),\n",
    "                hovertemplate='%{y}<br>%{x}: %{z:+.3f}<extra></extra>',\n",
    "            ))\n",
    "            h = max(STYLE['chart_height'], len(hm_data) * 26)\n",
    "            fig.update_layout(**base_layout(height=h, margin=dict(l=160, r=80, t=20, b=50)),\n",
    "                               yaxis=styled_axis(''))\n",
    "            save_html(fig, CHART_VAL_DIR / 'color_importance_heatmap.html')\n",
    "\n",
    "    # ---- Chart 4: Female vs male butterfly chart ----\n",
    "    print(\"\\nGenerating female vs male color comparison...\")\n",
    "    if 'female' in freq_pct_filtered.index and 'male' in freq_pct_filtered.index:\n",
    "        fem = freq_pct_filtered.loc['female']\n",
    "        mal = freq_pct_filtered.loc['male']\n",
    "        all_colors = sorted(set(fem.index) | set(mal.index),\n",
    "                            key=lambda c: fem.get(c, 0) + mal.get(c, 0), reverse=True)[:18]\n",
    "\n",
    "        fig = go.Figure()\n",
    "        y_labels = [c.replace('_', ' ').title() for c in all_colors]\n",
    "\n",
    "        for i, cname in enumerate(all_colors):\n",
    "            f_val = fem.get(cname, 0)\n",
    "            m_val = mal.get(cname, 0)\n",
    "            hex_c = rgb_hex(cname)\n",
    "            ec = edge_color_for(cname) if edge_color_for(cname) != 'none' else 'rgba(0,0,0,0)'\n",
    "            # Female (left, negative x)\n",
    "            fig.add_trace(go.Bar(\n",
    "                y=[y_labels[i]], x=[-f_val], orientation='h',\n",
    "                marker=dict(color=hex_c, opacity=0.85, line=dict(width=0.6, color=ec)),\n",
    "                text=f'{f_val:.1f}%' if f_val > 1 else '',\n",
    "                textposition='outside', textfont=dict(size=8, color='#555'),\n",
    "                hovertemplate=f'{cname}<br>Female: {f_val:.1f}%<extra></extra>',\n",
    "                showlegend=False,\n",
    "            ))\n",
    "            # Male (right, positive x)\n",
    "            fig.add_trace(go.Bar(\n",
    "                y=[y_labels[i]], x=[m_val], orientation='h',\n",
    "                marker=dict(color=hex_c, opacity=0.85, line=dict(width=0.6, color=ec)),\n",
    "                text=f'{m_val:.1f}%' if m_val > 1 else '',\n",
    "                textposition='outside', textfont=dict(size=8, color='#555'),\n",
    "                hovertemplate=f'{cname}<br>Male: {m_val:.1f}%<extra></extra>',\n",
    "                showlegend=False,\n",
    "            ))\n",
    "\n",
    "        fig.add_vline(x=0, line=dict(color='#1a1a1a', width=0.8))\n",
    "        x_max = max(fem.max(), mal.max()) * 1.3\n",
    "        fig.add_annotation(x=-x_max * 0.3, y=-0.08, yref='paper',\n",
    "                           text='<b>\\u2190 Female</b>', showarrow=False,\n",
    "                           font=dict(size=11, color='#c44e52'))\n",
    "        fig.add_annotation(x=x_max * 0.3, y=-0.08, yref='paper',\n",
    "                           text='<b>Male \\u2192</b>', showarrow=False,\n",
    "                           font=dict(size=11, color='#4c72b0'))\n",
    "        h = max(STYLE['chart_height'], len(all_colors) * 28)\n",
    "        fig.update_layout(**base_layout(height=h, margin=dict(l=120, r=60, t=20, b=60)),\n",
    "                           xaxis=styled_axis('Share of products (%)',\n",
    "                                             range=[-x_max, x_max],\n",
    "                                             tickvals=np.arange(-int(x_max), int(x_max)+1, 5).tolist(),\n",
    "                                             ticktext=[str(abs(v)) for v in\n",
    "                                                       np.arange(-int(x_max), int(x_max)+1, 5)]),\n",
    "                           yaxis=styled_axis('', autorange='reversed'),\n",
    "                           barmode='relative')\n",
    "        save_html(fig, CHART_VAL_DIR / 'color_comparison_butterfly.html')\n",
    "\n",
    "    print(f\"\\nAll charts saved to {CHART_VAL_DIR}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN ENTRY POINT\n",
    "# ============================================================================\n",
    "\n",
    "STAGE_MAP = {\n",
    "    '1': ('Color extraction', run_color_extraction),\n",
    "    '2': ('ML gender prediction', run_ml_pipeline),\n",
    "    '3': ('Regression analysis', run_regression_analysis),\n",
    "    '4': ('Color visualisations', run_color_charts),\n",
    "}\n",
    "\n",
    "\n",
    "def run_pipeline(stages='all'):\n",
    "    \"\"\"\n",
    "    Run one or more pipeline stages.\n",
    "\n",
    "    Args:\n",
    "        stages: '1', '2', '3', '4', 'all', or a list like ['2', '3'].\n",
    "                Can also pass ints: run_pipeline(3) or run_pipeline([2, 3]).\n",
    "    \n",
    "    Examples (notebook):\n",
    "        run_pipeline('all')\n",
    "        run_pipeline(2)\n",
    "        run_pipeline([2, 3])\n",
    "        run_pipeline('3,4')\n",
    "    \"\"\"\n",
    "    if stages == 'all':\n",
    "        stage_list = ['1', '2', '3', '4']\n",
    "    elif isinstance(stages, (list, tuple)):\n",
    "        stage_list = [str(s) for s in stages]\n",
    "    elif isinstance(stages, int):\n",
    "        stage_list = [str(stages)]\n",
    "    else:\n",
    "        stage_list = [s.strip() for s in str(stages).split(',')]\n",
    "\n",
    "    for stage in stage_list:\n",
    "        if stage not in STAGE_MAP:\n",
    "            print(f\"Unknown stage: {stage}. Choose from 1, 2, 3, 4, or 'all'.\")\n",
    "            continue\n",
    "        name, func = STAGE_MAP[stage]\n",
    "        print(f\"\\n{'#' * 70}\")\n",
    "        print(f\"# RUNNING STAGE {stage}: {name.upper()}\")\n",
    "        print(f\"{'#' * 70}\\n\")\n",
    "        try:\n",
    "            func()\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\nStage {stage} interrupted.\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nStage {stage} failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_pipeline('2,3,4')\n",
    "    print(\"Usage: run_pipeline(stages) where stages = 1, 2, 3, 4, or 'all'\")\n",
    "    print(\"  e.g. run_pipeline(2)  or  run_pipeline([2, 3])  or  run_pipeline('all')\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
