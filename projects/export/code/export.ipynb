{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e306899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FILE PATHS - edit these to match your local setup\n",
    "# ============================================================================\n",
    "DATA_PATH = '/Users/leoss/Desktop/Portfolio/Website-/projects/export/data/atlas_2022.dta'\n",
    "SAVE_DIR  = '/Users/leoss/Desktop/Portfolio/Website-/projects/export/outputs'\n",
    "\n",
    "# External product/sector lookup (from PP413 project data)\n",
    "SECTOR_LOOKUP_PATH = \"/Users/leoss/Desktop/Portfolio/Website-/projects/export/data/unique_hs_codes_and_sectors.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3688122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import plotly.express as px\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52090f82",
   "metadata": {},
   "source": [
    "# Trade Analysis Framework - Italy\n",
    "Configurable pipeline for trade data from the Atlas of Economic Complexity.  \n",
    "Produces product-level and sector-level bar charts, time-series trends, opportunity scatter plots, and treemaps.\n",
    "\n",
    "**Changelog vs. previous version:**\n",
    "- Fixed: strategy weights now match the report formulas (LHF, Balanced, Long Jumps)\n",
    "- Fixed: product names no longer stuck in lowercase (uses external CSV lookup instead of manual dict)\n",
    "- Fixed: `reversed_normalized_distance` now uses standard `1 - norm` formula\n",
    "- Fixed: sector PCI aggregation handles zero-weight edge cases\n",
    "- Fixed: sector_mapping filtered to base year to prevent merge duplicates\n",
    "- Fixed: net_export time-series PCI uses `export_value` weights instead of clipped net exports\n",
    "- Improved: removed manual 30-product name mapping; all 1241 products resolved via lookup CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c699190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    'data': {\n",
    "        'path': DATA_PATH,\n",
    "        'country_code': 'ITA',\n",
    "        'country_name': 'Italy',\n",
    "        'sector_lookup': SECTOR_LOOKUP_PATH,  # external clean product names\n",
    "    },\n",
    "    'analysis': {\n",
    "        'base_year': 2022,\n",
    "        'time_range': (1995, 2022),\n",
    "        'value_metrics': ['export_value', 'net_export'],\n",
    "        'rolling_window': 5,\n",
    "        'top_n': 10,\n",
    "    },\n",
    "    'opportunities': {\n",
    "        'enabled': True,\n",
    "        'min_pci': 1.49,\n",
    "        'max_rca': 1.0,\n",
    "        # FIX: weights now match report Appendix 3F formulas exactly\n",
    "        'strategies': {\n",
    "            'lhf': {'distance': 0.75, 'pci': 0.10, 'cog': 0.15},   # Low Hanging Fruit\n",
    "            'bs':  {'distance': 0.50, 'pci': 0.25, 'cog': 0.25},   # Balanced Strategy\n",
    "            'lj':  {'distance': 0.40, 'pci': 0.20, 'cog': 0.40},   # Long Jumps / Strategic Bets\n",
    "        }\n",
    "    },\n",
    "    'visualization': {\n",
    "        'save_format': 'png',\n",
    "        'dpi': 300,\n",
    "        'figure_sizes': {\n",
    "            'bar': (14, 8),\n",
    "            'line': (16, 8),\n",
    "            'scatter': (14, 8.5),\n",
    "        },\n",
    "        'color_palette': 'husl',\n",
    "        'font_family': 'Arial',\n",
    "    },\n",
    "    'output': {\n",
    "        'directory': SAVE_DIR,\n",
    "        'create_treemap': True,\n",
    "        'treemap_year': 1995,\n",
    "        'export_csv': True,\n",
    "    },\n",
    "    'advanced': {\n",
    "        'exclude_sectors': ['Other'],\n",
    "        'min_export_threshold': 1e6,\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9d9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATA LOADING AND PREPARATION\n",
    "# ============================================================================\n",
    "\n",
    "class TradeDataLoader:\n",
    "    \"\"\"Loads Atlas .dta and applies clean product names from external lookup.\"\"\"\n",
    "\n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.data_cfg = config['data']\n",
    "        self.adv_cfg  = config['advanced']\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def load_data(self) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, Dict]:\n",
    "        print(f\"Loading data from: {self.data_cfg['path']}\")\n",
    "        df = pd.read_stata(self.data_cfg['path'])\n",
    "\n",
    "        # net exports\n",
    "        df['net_export'] = df['export_value'] - df['import_value']\n",
    "\n",
    "        if 'country_id' in df.columns:\n",
    "            df = df.drop(columns='country_id')\n",
    "\n",
    "        for sector in self.adv_cfg['exclude_sectors']:\n",
    "            df = df[df['sector_name'] != sector]\n",
    "\n",
    "        # ---- FIX: apply clean product names from external CSV ----------\n",
    "        # Instead of a manual 30-entry dict + lowercase, join on hs_92_code\n",
    "        # so every product gets a properly cased short name.\n",
    "        lookup_path = self.data_cfg.get('sector_lookup')\n",
    "        if lookup_path and os.path.exists(lookup_path):\n",
    "            # read raw bytes, strip NUL chars, then parse\n",
    "            with open(lookup_path, 'rb') as fh:\n",
    "                raw = fh.read().replace(b'\\x00', b'')\n",
    "            from io import StringIO\n",
    "            lookup = pd.read_csv(\n",
    "            StringIO(raw.decode('latin-1')),\n",
    "            sep=',',\n",
    "            engine='python',\n",
    "            on_bad_lines='warn',\n",
    "            )\n",
    "            print(f\"  lookup columns: {list(lookup.columns)}\")\n",
    "            print(f\"  lookup shape: {lookup.shape}\")\n",
    "            # rename to avoid collision during merge\n",
    "            lookup = lookup.rename(columns={\n",
    "                'product_name': 'clean_name',\n",
    "                'sector_name':  'clean_sector',\n",
    "            })\n",
    "            lookup['hs_92_code'] = lookup['hs_92_code'].astype(str)\n",
    "            df['hs_92_code'] = df['hs_92_code'].astype(str)\n",
    "            df = df.merge(\n",
    "                lookup[['hs_92_code', 'clean_name']],\n",
    "                on='hs_92_code', how='left'\n",
    "            )\n",
    "            # use clean name where available, else keep original\n",
    "            df['product_name'] = df['clean_name'].fillna(df['product_name'])\n",
    "            df = df.drop(columns='clean_name')\n",
    "            print(f\"  applied clean product names from {os.path.basename(lookup_path)}\")\n",
    "        else:\n",
    "            print(\"  WARNING: sector lookup CSV not found; using raw Atlas names\")\n",
    "\n",
    "        # ---- split country vs rest-of-world ----\n",
    "        code = self.data_cfg['country_code']\n",
    "        country_df = df[df['iso3_code'] == code].copy()\n",
    "        global_df  = df[df['iso3_code'] != code].copy()\n",
    "\n",
    "        global_df = global_df[[\n",
    "            'name_short_en', 'iso3_code', 'year',\n",
    "            'sector', 'sector_name', 'product_name', 'hs_92_code', 'product_level',\n",
    "            'export_value', 'import_value', 'net_export', 'global_market_share',\n",
    "            'export_rca', 'pci', 'distance', 'cog'\n",
    "        ]]\n",
    "\n",
    "        # FIX: sector_mapping from base_year only to avoid merge duplicates\n",
    "        base_year = self.config['analysis']['base_year']\n",
    "        sector_mapping = (\n",
    "            country_df[country_df['year'] == base_year]\n",
    "            [['hs_92_code', 'product_name', 'sector_name']]\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "\n",
    "        sector_colors = self._sector_colors(country_df)\n",
    "\n",
    "        print(f\"  data loaded: {self.data_cfg['country_name']} \"\n",
    "              f\"({len(country_df):,} obs), Global ({len(global_df):,} obs)\")\n",
    "        print(f\"  years: {country_df['year'].min()}-{country_df['year'].max()}\")\n",
    "        print(f\"  sectors: {', '.join(sorted(country_df['sector_name'].unique()))}\")\n",
    "\n",
    "        return country_df, global_df, sector_mapping, sector_colors\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def _sector_colors(self, df: pd.DataFrame) -> Dict:\n",
    "        sectors = sorted(df['sector_name'].unique())\n",
    "        pal = sns.color_palette(self.config['visualization']['color_palette'],\n",
    "                                n_colors=len(sectors))\n",
    "        return dict(zip(sectors, pal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "160b5db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# METRICS CALCULATION\n",
    "# ============================================================================\n",
    "\n",
    "class MetricsCalculator:\n",
    "    \"\"\"Product-level and sector-level trade metrics.\"\"\"\n",
    "\n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def calculate_product_metrics(self, country_data, global_ref, value_col):\n",
    "        agg = (\n",
    "            country_data\n",
    "            .groupby(['hs_92_code', 'product_name', 'sector_name'])\n",
    "            .agg({\n",
    "                value_col: 'sum',\n",
    "                'export_rca': 'max',\n",
    "                'pci': 'first',\n",
    "                'distance': 'first',\n",
    "                'cog': 'first',\n",
    "            })\n",
    "            .reset_index()\n",
    "            .rename(columns={'export_rca': 'rca'})\n",
    "        )\n",
    "        ref = global_ref[['hs_92_code', 'global_value', 'pci_rank']].copy()\n",
    "        merged = agg.merge(ref, on='hs_92_code', how='left')\n",
    "        merged['market_share']   = (merged[value_col] / merged['global_value']) * 100\n",
    "        merged['pci_percentile'] = merged['pci_rank']\n",
    "        merged = merged.drop(columns='pci_rank')\n",
    "        return merged\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def prepare_global_reference(self, country_data, global_data, year, value_col):\n",
    "        cy = country_data[country_data['year'] == year]\n",
    "        gy = global_data[global_data['year'] == year]\n",
    "\n",
    "        combined = pd.concat([gy, cy])\n",
    "        gref = combined.groupby('hs_92_code')[value_col].sum().reset_index(name='global_value')\n",
    "\n",
    "        gpci = gy[['hs_92_code', 'pci']].drop_duplicates()\n",
    "        gref = gref.merge(gpci, on='hs_92_code', how='left')\n",
    "        gref['pci_rank'] = gref['pci'].rank(pct=True) * 100\n",
    "        return gref\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def calculate_sector_metrics_timeseries(self, country_df, global_df, value_col):\n",
    "        \"\"\"Sector-level metrics over time with rolling averages.\n",
    "\n",
    "        FIX: PCI weighting always uses export_value (positive) even when\n",
    "        value_col is net_export, to avoid zero/negative weight issues.\n",
    "        \"\"\"\n",
    "        rw = self.config['analysis']['rolling_window']\n",
    "        weight_col = 'export_value'  # always positive\n",
    "\n",
    "        country_export = (\n",
    "            country_df.groupby(['sector_name', 'year'])[value_col]\n",
    "            .sum().reset_index(name='country_value')\n",
    "        )\n",
    "        global_export = (\n",
    "            global_df.groupby(['sector_name', 'year'])[value_col]\n",
    "            .sum().reset_index(name='global_value')\n",
    "        )\n",
    "\n",
    "        # weighted PCI - use export_value weights for stability\n",
    "        def safe_wavg(g):\n",
    "            w = g[weight_col].clip(lower=0)\n",
    "            if w.sum() == 0:\n",
    "                return pd.Series({'pci': np.nan})\n",
    "            return pd.Series({'pci': np.average(g['pci'], weights=w)})\n",
    "\n",
    "        pci_metrics = (\n",
    "            country_df.groupby(['sector_name', 'year'])\n",
    "            .apply(safe_wavg)\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        metrics = (\n",
    "            country_export\n",
    "            .merge(global_export, on=['sector_name', 'year'])\n",
    "            .merge(pci_metrics, on=['sector_name', 'year'])\n",
    "        )\n",
    "\n",
    "        # RCA\n",
    "        tc = country_df.groupby('year')[value_col].sum().reset_index(name='total_country')\n",
    "        tg = global_df.groupby('year')[value_col].sum().reset_index(name='total_global')\n",
    "        metrics = (\n",
    "            metrics.merge(tc, on='year').merge(tg, on='year')\n",
    "            .assign(\n",
    "                market_share=lambda x: (x['country_value'] / x['global_value']) * 100,\n",
    "                rca=lambda x: (x['country_value'] / x['total_country']) /\n",
    "                              (x['global_value'] / x['total_global']),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # rolling averages\n",
    "        metrics = metrics.sort_values(['sector_name', 'year'])\n",
    "        for src, dst in [('country_value', 'rolling_value'),\n",
    "                         ('market_share',  'rolling_market_share'),\n",
    "                         ('pci',           'rolling_pci'),\n",
    "                         ('rca',           'rolling_rca')]:\n",
    "            metrics[dst] = (\n",
    "                metrics.groupby('sector_name', group_keys=False)[src]\n",
    "                .transform(lambda s: s.rolling(rw, min_periods=1).mean())\n",
    "            )\n",
    "        metrics = metrics.rename(columns={'country_value': value_col})\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7b31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPPORTUNITY ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "class OpportunityAnalyzer:\n",
    "    \"\"\"Identifies new export opportunities using strategic frameworks.\"\"\"\n",
    "\n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.opp = config['opportunities']\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def analyze_opportunities(self, country_data, global_data):\n",
    "        if not self.opp['enabled']:\n",
    "            return pd.DataFrame(), {}\n",
    "\n",
    "        opps = country_data[\n",
    "            (country_data['export_rca'] < self.opp['max_rca']) &\n",
    "            (country_data['pci'] > self.opp['min_pci'])\n",
    "        ].copy()\n",
    "\n",
    "        if opps.empty:\n",
    "            print(\"Warning: no opportunities found with current criteria\")\n",
    "            return opps, {}\n",
    "\n",
    "        opps = self._normalize(opps)\n",
    "\n",
    "        # add global export size for bubble sizing\n",
    "        gexp = global_data.groupby('hs_92_code')['export_value'].sum().reset_index()\n",
    "        opps = opps.merge(\n",
    "            gexp.rename(columns={'export_value': 'global_export_value'}),\n",
    "            on='hs_92_code', how='left'\n",
    "        )\n",
    "        opps = self._score(opps)\n",
    "\n",
    "        top_n = self.config['analysis']['top_n']\n",
    "        top = {s: opps.nlargest(top_n, s) for s in self.opp['strategies']}\n",
    "        return opps, top\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def _normalize(self, df):\n",
    "        def minmax(s):\n",
    "            r = s.max() - s.min()\n",
    "            return (s - s.min()) / r if r > 0 else s * 0\n",
    "        df['norm_distance'] = minmax(df['distance'])\n",
    "        df['norm_pci']      = minmax(df['pci'])\n",
    "        df['norm_cog']      = minmax(df['cog'])\n",
    "        # FIX: standard reversal so 1 = closest, 0 = furthest\n",
    "        df['norm_proximity'] = 1 - df['norm_distance']\n",
    "        return df\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def _score(self, df):\n",
    "        for name, w in self.opp['strategies'].items():\n",
    "            df[name] = (\n",
    "                df['norm_proximity'] * w['distance'] +\n",
    "                df['norm_pci']       * w['pci'] +\n",
    "                df['norm_cog']       * w['cog']\n",
    "            )\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b27930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION (redesigned - unified theme)\n",
    "# ============================================================================\n",
    "#\n",
    "# Changes from original:\n",
    "#   - Curated 9-sector palette replacing random husl\n",
    "#   - Consistent typography hierarchy: title 16pt semibold, axis 11pt, ticks 10pt\n",
    "#   - Uniform grid: light gray dashed, alpha 0.25\n",
    "#   - White background with subtle spine styling (left + bottom only, gray)\n",
    "#   - Consistent legend style: frameon, top-right outside, matching font\n",
    "#   - Bar value annotations outside bars (dark gray) instead of inside (white)\n",
    "#   - Line charts: thicker lines (2.5), smaller markers (5), area fill at alpha 0.04\n",
    "#   - Scatter: consistent with line/bar chrome\n",
    "#   - Fixed: net export time-series filenames now include prefix (no overwrite)\n",
    "#   - Fixed: NaN/inf filter before bar plotting to suppress posx/posy warnings\n",
    "#   - Treemap: matching color palette via rgb strings\n",
    "# ============================================================================\n",
    "\n",
    "class Visualizer:\n",
    "    \"\"\"All chart types for the trade analysis - unified theme.\"\"\"\n",
    "\n",
    "    # ---- curated palette: 9 distinct, colourblind-friendly, muted tones ----\n",
    "    SECTOR_PALETTE = {\n",
    "        'Agriculture':  '#5B8C5A',   # sage green\n",
    "        'Chemicals':    '#E07A5F',   # terracotta\n",
    "        'Electronics':  '#3D405B',   # charcoal blue\n",
    "        'Machinery':    '#81B29A',   # seafoam\n",
    "        'Metals':       '#F2CC8F',   # warm sand\n",
    "        'Minerals':     '#A8896C',   # taupe\n",
    "        'Stone':        '#B0A8B9',   # lavender gray\n",
    "        'Textiles':     '#C97C5D',   # burnt sienna\n",
    "        'Vehicles':     '#577399',   # steel blue\n",
    "    }\n",
    "\n",
    "    # ---- theme constants ----\n",
    "    BG          = '#FFFFFF'\n",
    "    GRID_COLOR  = '#D5D8DC'\n",
    "    SPINE_COLOR = '#B0B3B8'\n",
    "    TEXT_DARK   = '#2C3E50'\n",
    "    TEXT_MID    = '#5D6D7E'\n",
    "    TEXT_LIGHT  = '#95A5A6'\n",
    "    ANNOT_COLOR = '#34495E'\n",
    "\n",
    "    FONT_TITLE  = 16\n",
    "    FONT_AXIS   = 11\n",
    "    FONT_TICK   = 10\n",
    "    FONT_ANNOT  = 9\n",
    "    FONT_LEGEND = 9.5\n",
    "\n",
    "    def __init__(self, config: Dict, sector_colors: Dict):\n",
    "        self.config  = config\n",
    "        # override the husl palette with curated one; fall back for unknown sectors\n",
    "        self.colors  = {s: self.SECTOR_PALETTE.get(s, c)\n",
    "                        for s, c in sector_colors.items()}\n",
    "        self.viz     = config['visualization']\n",
    "        self.out_dir = config['output']['directory']\n",
    "        os.makedirs(self.out_dir, exist_ok=True)\n",
    "        self._apply_rcparams()\n",
    "\n",
    "    def _apply_rcparams(self):\n",
    "        plt.rcParams.update({\n",
    "            'font.family':       self.viz['font_family'],\n",
    "            'figure.facecolor':  self.BG,\n",
    "            'axes.facecolor':    self.BG,\n",
    "            'axes.edgecolor':    self.SPINE_COLOR,\n",
    "            'axes.linewidth':    0.8,\n",
    "            'axes.grid':         True,\n",
    "            'grid.color':        self.GRID_COLOR,\n",
    "            'grid.linestyle':    '--',\n",
    "            'grid.linewidth':    0.5,\n",
    "            'grid.alpha':        0.25,\n",
    "            'axes.spines.top':   False,\n",
    "            'axes.spines.right': False,\n",
    "            'axes.labelcolor':   self.TEXT_DARK,\n",
    "            'xtick.color':       self.TEXT_MID,\n",
    "            'ytick.color':       self.TEXT_MID,\n",
    "            'xtick.labelsize':   self.FONT_TICK,\n",
    "            'ytick.labelsize':   self.FONT_TICK,\n",
    "            'legend.frameon':    True,\n",
    "            'legend.edgecolor':  self.GRID_COLOR,\n",
    "            'legend.facecolor':  self.BG,\n",
    "            'legend.fontsize':   self.FONT_LEGEND,\n",
    "        })\n",
    "\n",
    "    # ---- save helper ----\n",
    "    def _save(self, fig, filename):\n",
    "        fig.savefig(os.path.join(self.out_dir, filename),\n",
    "                    bbox_inches='tight', dpi=self.viz['dpi'],\n",
    "                    facecolor=self.BG, edgecolor='none')\n",
    "        plt.close(fig)\n",
    "        print(f\"  saved: {filename}\")\n",
    "\n",
    "    # ---- sector legend (shared across chart types) ----\n",
    "    def _sector_legend(self, ax, sectors, style='patch', loc='outside_right'):\n",
    "        if style == 'patch':\n",
    "            handles = [plt.Rectangle((0, 0), 1, 1, color=self.colors.get(s, '#CCC'))\n",
    "                       for s in sectors]\n",
    "        else:\n",
    "            handles = [plt.Line2D([0], [0], marker='o', color=self.colors.get(s, '#CCC'),\n",
    "                                  markersize=8, linewidth=2.2) for s in sectors]\n",
    "\n",
    "        kwargs = dict(handles=handles, labels=list(sectors),\n",
    "                      title='Sector', title_fontsize=self.FONT_LEGEND,\n",
    "                      fontsize=self.FONT_LEGEND, frameon=True,\n",
    "                      edgecolor=self.GRID_COLOR, facecolor=self.BG)\n",
    "        if loc == 'outside_right':\n",
    "            kwargs.update(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "        elif loc == 'lower_right':\n",
    "            kwargs.update(loc='lower right')\n",
    "        ax.legend(**kwargs)\n",
    "\n",
    "    # ---- value formatter ----\n",
    "    @staticmethod\n",
    "    def _fmt_value(val, is_usd=False):\n",
    "        \"\"\"Compact number formatter for annotations.\"\"\"\n",
    "        if not np.isfinite(val):\n",
    "            return ''\n",
    "        if is_usd:\n",
    "            if abs(val) >= 1e9:\n",
    "                return f'${val/1e9:.1f}B'\n",
    "            if abs(val) >= 1e6:\n",
    "                return f'${val/1e6:.0f}M'\n",
    "            return f'${val:,.0f}'\n",
    "        if abs(val) >= 100:\n",
    "            return f'{val:,.0f}'\n",
    "        if abs(val) >= 1:\n",
    "            return f'{val:.1f}'\n",
    "        return f'{val:.2f}'\n",
    "\n",
    "    # ======================================================================\n",
    "    # BAR CHARTS\n",
    "    # ======================================================================\n",
    "    def plot_product_bars(self, top_products, value_col, labels):\n",
    "        prefix = 'net_' if value_col == 'net_export' else ''\n",
    "        is_usd = value_col in ('export_value', 'net_export')\n",
    "        specs = [\n",
    "            ('volume',       value_col,      labels['volume'],       f'{prefix}exports_value_product.png',  is_usd),\n",
    "            ('rca',          'rca',          labels['rca'],          f'{prefix}exports_rca_product.png',    False),\n",
    "            ('market_share', 'market_share', labels['market_share'], f'{prefix}exports_ms_product.png',     False),\n",
    "            ('pci',          'pci',          labels['pci'],          f'{prefix}exports_pci_product.png',    False),\n",
    "        ]\n",
    "        for cat, xcol, xlab, fname, usd in specs:\n",
    "            data = top_products[cat]\n",
    "            if not data.empty:\n",
    "                self._bar(data, xcol, xlab, fname, is_usd=usd)\n",
    "\n",
    "    def plot_sector_bars(self, sector_metrics, value_col, labels):\n",
    "        prefix = 'net_' if value_col == 'net_export' else ''\n",
    "        name = self.config['data']['country_name']\n",
    "        is_usd = value_col in ('export_value', 'net_export')\n",
    "        for metric, lab, fname, usd in [\n",
    "            (value_col,      labels['volume'],       f'{prefix}sector_value.png', is_usd),\n",
    "            ('rca',          labels['rca'],          f'{prefix}sector_rca.png',   False),\n",
    "            ('market_share', labels['market_share'], f'{prefix}sector_ms.png',    False),\n",
    "            ('pci',          labels['pci'],          f'{prefix}sector_pci.png',   False),\n",
    "        ]:\n",
    "            d = sector_metrics.sort_values(metric, ascending=False)\n",
    "            self._bar(d, metric, lab, fname, is_usd=usd, y_col='sector_name',\n",
    "                      title=f\"{name} Sectors by {lab}\")\n",
    "\n",
    "    def _bar(self, data, x, xlabel, filename, is_usd=False,\n",
    "             y_col='product_name', title=None):\n",
    "        # filter non-finite values to avoid posx/posy warnings\n",
    "        data = data[np.isfinite(data[x])].copy()\n",
    "        if data.empty:\n",
    "            return\n",
    "\n",
    "        data = data.sort_values(x, ascending=True)  # ascending for horizontal bars\n",
    "        n = len(data)\n",
    "        fig_h = max(4, 0.55 * n + 1.8)\n",
    "        fig, ax = plt.subplots(figsize=(12, fig_h))\n",
    "\n",
    "        colors = [self.colors.get(s, '#CCC') for s in data['sector_name']]\n",
    "        y_pos = np.arange(n)\n",
    "\n",
    "        ax.barh(y_pos, data[x].values, color=colors, height=0.65,\n",
    "                edgecolor='white', linewidth=0.5, zorder=3)\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(data[y_col].values, fontsize=self.FONT_TICK)\n",
    "\n",
    "        # value annotations outside bars\n",
    "        x_max = data[x].max()\n",
    "        for i, val in enumerate(data[x].values):\n",
    "            label = self._fmt_value(val, is_usd=is_usd)\n",
    "            offset = x_max * 0.01\n",
    "            ax.text(val + offset, i, label,\n",
    "                    va='center', ha='left', fontsize=self.FONT_ANNOT,\n",
    "                    color=self.ANNOT_COLOR, fontweight='medium')\n",
    "\n",
    "        # expand x-axis slightly for annotation room\n",
    "        ax.set_xlim(left=min(0, data[x].min()), right=x_max * 1.15)\n",
    "\n",
    "        ax.set_xlabel(xlabel, fontsize=self.FONT_AXIS, color=self.TEXT_DARK)\n",
    "        ax.set_title(title or f\"Top {n} by {xlabel}\",\n",
    "                     fontsize=self.FONT_TITLE, fontweight='semibold',\n",
    "                     color=self.TEXT_DARK, pad=12)\n",
    "        ax.tick_params(axis='y', length=0)\n",
    "        ax.grid(axis='x', alpha=0.2)\n",
    "        ax.grid(axis='y', visible=False)\n",
    "\n",
    "        sectors = data['sector_name'].unique()\n",
    "        self._sector_legend(ax, sectors, loc='lower_right')\n",
    "\n",
    "        fig.tight_layout()\n",
    "        self._save(fig, filename)\n",
    "\n",
    "    # ======================================================================\n",
    "    # TIME TRENDS\n",
    "    # ======================================================================\n",
    "    def plot_time_trends(self, sector_metrics, value_col):\n",
    "        # FIX: prefix ALL filenames for net export to avoid overwriting gross\n",
    "        prefix = 'net_' if value_col == 'net_export' else ''\n",
    "        rw = self.config['analysis']['rolling_window']\n",
    "\n",
    "        for ycol, title, ylab, fname in [\n",
    "            ('rolling_value',        'Export Volume',      value_col.replace('_', ' ').title(),\n",
    "             f'{prefix}export_value_trends.png'),\n",
    "            ('rolling_pci',          'Product Complexity', 'Weighted PCI',\n",
    "             f'{prefix}pci_trends.png'),\n",
    "            ('rolling_rca',          'Revealed Comparative Advantage', 'RCA Score',\n",
    "             f'{prefix}rca_trends.png'),\n",
    "            ('rolling_market_share', 'Global Market Share', 'Market Share (%)',\n",
    "             f'{prefix}market_share_trends.png'),\n",
    "        ]:\n",
    "            fig, ax = plt.subplots(figsize=(14, 6.5))\n",
    "\n",
    "            for sector in sorted(sector_metrics['sector_name'].unique()):\n",
    "                sd = sector_metrics[sector_metrics['sector_name'] == sector].sort_values('year')\n",
    "                c = self.colors.get(sector, '#CCC')\n",
    "                ax.plot(sd['year'], sd[ycol], color=c, linewidth=2.2,\n",
    "                        marker='o', markersize=4, markeredgecolor='white',\n",
    "                        markeredgewidth=0.8, label=sector, zorder=3)\n",
    "                ax.fill_between(sd['year'], sd[ycol], alpha=0.04, color=c, zorder=1)\n",
    "\n",
    "            ax.set_title(f'{title} ({rw}-Year Rolling Average)',\n",
    "                         fontsize=self.FONT_TITLE, fontweight='semibold',\n",
    "                         color=self.TEXT_DARK, pad=12)\n",
    "            ax.set_ylabel(ylab, fontsize=self.FONT_AXIS, color=self.TEXT_DARK)\n",
    "            ax.set_xlabel('')\n",
    "            ax.tick_params(axis='both', labelsize=self.FONT_TICK)\n",
    "\n",
    "            sectors = sorted(sector_metrics['sector_name'].unique())\n",
    "            self._sector_legend(ax, sectors, style='line', loc='outside_right')\n",
    "\n",
    "            fig.tight_layout()\n",
    "            self._save(fig, fname)\n",
    "\n",
    "    # ======================================================================\n",
    "    # OPPORTUNITY SCATTER\n",
    "    # ======================================================================\n",
    "    def plot_opportunities(self, top_opps, strategy_titles):\n",
    "        for strat, data in top_opps.items():\n",
    "            if data.empty:\n",
    "                continue\n",
    "            self._opp_scatter(data, strategy_titles[strat])\n",
    "\n",
    "    def _opp_scatter(self, data, title):\n",
    "        fig, ax = plt.subplots(figsize=(13, 8))\n",
    "\n",
    "        # size scaling\n",
    "        gmin, gmax = data['global_export_value'].min(), data['global_export_value'].max()\n",
    "        rng = gmax - gmin if gmax > gmin else 1\n",
    "        sizes = 120 + (data['global_export_value'] - gmin) / rng * 1400\n",
    "\n",
    "        for sector in data['sector_name'].unique():\n",
    "            sd = data[data['sector_name'] == sector]\n",
    "            idx = sd.index\n",
    "            ax.scatter(sd['norm_distance'], sd['norm_pci'],\n",
    "                       s=sizes.loc[idx], color=self.colors.get(sector, '#CCC'),\n",
    "                       alpha=0.65, edgecolors='white', linewidth=0.8, zorder=3)\n",
    "\n",
    "        # labels\n",
    "        texts = []\n",
    "        for _, row in data.iterrows():\n",
    "            texts.append(ax.text(\n",
    "                row['norm_distance'], row['norm_pci'],\n",
    "                row['product_name'], fontsize=8, color=self.TEXT_DARK,\n",
    "                ha='center', va='center',\n",
    "                bbox=dict(facecolor='white', edgecolor='none',\n",
    "                          alpha=0.85, pad=1.2, boxstyle='round,pad=0.3')\n",
    "            ))\n",
    "        try:\n",
    "            adjust_text(texts, arrowprops=dict(arrowstyle='-', color=self.TEXT_LIGHT, lw=0.6),\n",
    "                        expand_points=(1.3, 1.5), expand_text=(1.2, 1.4),\n",
    "                        force_text=(0.5, 0.8))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        ax.set_title(title, fontsize=self.FONT_TITLE, fontweight='semibold',\n",
    "                     color=self.TEXT_DARK, pad=14)\n",
    "        ax.set_xlabel('Normalized Distance (lower = closer to current exports)',\n",
    "                      fontsize=self.FONT_AXIS, color=self.TEXT_DARK)\n",
    "        ax.set_ylabel('Normalized Product Complexity',\n",
    "                      fontsize=self.FONT_AXIS, color=self.TEXT_DARK)\n",
    "\n",
    "        sectors = data['sector_name'].unique()\n",
    "        self._sector_legend(ax, sectors, style='patch', loc='outside_right')\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fname = f\"{title.replace(' ', '_')}.png\"\n",
    "        self._save(fig, fname)\n",
    "\n",
    "    # ======================================================================\n",
    "    # TREEMAP\n",
    "    # ======================================================================\n",
    "    def create_treemap(self, country_df, year):\n",
    "        if not self.config['output']['create_treemap']:\n",
    "            return\n",
    "        dy = country_df[country_df['year'] == year].copy()\n",
    "        if dy.empty:\n",
    "            print(f\"Warning: no data for treemap year {year}\")\n",
    "            return\n",
    "        dy = dy.dropna(subset=['export_value'])\n",
    "\n",
    "        stot = dy.groupby('sector_name')['export_value'].sum().reset_index()\n",
    "        total = stot['export_value'].sum()\n",
    "        stot['sector_share'] = (stot['export_value'] / total) * 100\n",
    "\n",
    "        dm = dy.merge(stot[['sector_name', 'sector_share']], on='sector_name')\n",
    "        dm['product_share_in_sector'] = (\n",
    "            dm['export_value'] /\n",
    "            dm.groupby('sector_name')['export_value'].transform('sum')\n",
    "        ) * 100\n",
    "        dm['overall_share'] = (dm['export_value'] / total) * 100\n",
    "        dm['parent'] = dm['sector_name']\n",
    "\n",
    "        # convert hex palette to rgb() strings for plotly\n",
    "        def hex_to_rgb(h):\n",
    "            h = h.lstrip('#')\n",
    "            return f'rgb({int(h[:2],16)},{int(h[2:4],16)},{int(h[4:6],16)})'\n",
    "\n",
    "        color_map = {s: hex_to_rgb(c) for s, c in self.colors.items()}\n",
    "\n",
    "        fig = px.treemap(\n",
    "            dm, path=['parent', 'product_name'], values='export_value',\n",
    "            color='sector_name', color_discrete_map=color_map,\n",
    "            hover_data={\n",
    "                'sector_share': ':.1f%',\n",
    "                'product_share_in_sector': ':.1f%',\n",
    "                'overall_share': ':.1f%',\n",
    "                'export_value': ':,',\n",
    "            },\n",
    "        )\n",
    "        name = self.config['data']['country_name']\n",
    "        fig.update_layout(\n",
    "            title={'text': f'{year} {name} Export Composition',\n",
    "                   'y': 0.95, 'x': 0.5, 'xanchor': 'center', 'yanchor': 'top',\n",
    "                   'font': {'size': 20, 'color': self.TEXT_DARK, 'family': 'Arial'}},\n",
    "            margin=dict(t=100, l=0, r=0, b=0),\n",
    "            paper_bgcolor=self.BG,\n",
    "            font={'family': 'Arial', 'color': self.TEXT_DARK},\n",
    "        )\n",
    "        fname = f'exports_{year}_treemap.html'\n",
    "        fig.write_html(os.path.join(self.out_dir, fname))\n",
    "        print(f\"  saved: {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7915ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "class TradeAnalysisPipeline:\n",
    "    \"\"\"Orchestrates the full analysis workflow.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config  = config\n",
    "        self.loader  = TradeDataLoader(config)\n",
    "        self.metrics = MetricsCalculator(config)\n",
    "        self.opps    = OpportunityAnalyzer(config)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def run(self):\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"TRADE ANALYSIS: {self.config['data']['country_name']}\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        country_df, global_df, sector_mapping, sector_colors = self.loader.load_data()\n",
    "        self.viz = Visualizer(self.config, sector_colors)\n",
    "\n",
    "        base_year    = self.config['analysis']['base_year']\n",
    "        value_metrics = self.config['analysis']['value_metrics']\n",
    "\n",
    "        country_year = country_df[country_df['year'] == base_year].merge(sector_mapping)\n",
    "        global_year  = global_df[global_df['year'] == base_year].merge(sector_mapping)\n",
    "\n",
    "        for vcol in value_metrics:\n",
    "            self._analyze_metric(country_df, global_df, country_year,\n",
    "                                 global_year, vcol, base_year)\n",
    "\n",
    "        # opportunity analysis (gross exports only)\n",
    "        if self.config['opportunities']['enabled']:\n",
    "            print(f\"\\n{'='*70}\\nNEW EXPORT OPPORTUNITIES\\n{'='*70}\")\n",
    "            opps, top = self.opps.analyze_opportunities(country_year, global_year)\n",
    "            if not opps.empty:\n",
    "                titles = {\n",
    "                    'lhf': 'Low Hanging Fruit Strategy',\n",
    "                    'bs':  'Balanced Strategy',\n",
    "                    'lj':  'Long Jumps Strategy',\n",
    "                }\n",
    "                self.viz.plot_opportunities(top, titles)\n",
    "                if self.config['output']['export_csv']:\n",
    "                    self._export_csv(top)\n",
    "\n",
    "        treemap_yr = self.config['output']['treemap_year']\n",
    "        self.viz.create_treemap(country_df, treemap_yr)\n",
    "\n",
    "        print(f\"\\n{'='*70}\\nANALYSIS COMPLETE\\n{'='*70}\")\n",
    "        print(f\"Outputs in: {self.config['output']['directory']}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def _analyze_metric(self, country_df, global_df, country_year,\n",
    "                        global_year, value_col, base_year):\n",
    "        name = value_col.replace('_',' ').title()\n",
    "        print(f\"\\n{'='*70}\\nANALYZING: {name}\\n{'='*70}\")\n",
    "\n",
    "        gref = self.metrics.prepare_global_reference(\n",
    "            country_year, global_year, base_year, value_col)\n",
    "\n",
    "        pmets = self.metrics.calculate_product_metrics(\n",
    "            country_year, gref, value_col)\n",
    "\n",
    "        top = self._top_products(pmets, value_col)\n",
    "        labels = {\n",
    "            'volume':       f'{name} (USD)',\n",
    "            'rca':          'Revealed Comparative Advantage',\n",
    "            'market_share': 'Global Market Share (%)',\n",
    "            'pci':          'Product Complexity Index',\n",
    "        }\n",
    "        self.viz.plot_product_bars(top, value_col, labels)\n",
    "\n",
    "        # sector aggregation\n",
    "        # FIX: safe weighted average for PCI that handles edge cases\n",
    "        def safe_wpci(grp):\n",
    "            w = pmets.loc[grp.index, value_col].clip(lower=0)\n",
    "            if w.sum() == 0:\n",
    "                return np.nan\n",
    "            return np.average(grp, weights=w)\n",
    "\n",
    "        smets = pmets.groupby('sector_name').agg({\n",
    "            value_col:       'sum',\n",
    "            'global_value':  'sum',\n",
    "            'rca':           'mean',\n",
    "            'pci':           safe_wpci,\n",
    "            'pci_percentile':'mean',\n",
    "        }).reset_index()\n",
    "        smets['market_share'] = (smets[value_col] / smets['global_value']) * 100\n",
    "        self.viz.plot_sector_bars(smets, value_col, labels)\n",
    "\n",
    "        # time series\n",
    "        ts = self.metrics.calculate_sector_metrics_timeseries(\n",
    "            country_df, global_df, value_col)\n",
    "        self.viz.plot_time_trends(ts, value_col)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def _top_products(self, pmets, value_col):\n",
    "        n   = self.config['analysis']['top_n']\n",
    "        thr = self.config['advanced']['min_export_threshold']\n",
    "        def top(df, col):\n",
    "            if df.empty or col not in df.columns:\n",
    "                return pd.DataFrame()\n",
    "            return df.sort_values(col, ascending=False).head(n).reset_index(drop=True)\n",
    "        return {\n",
    "            'volume':       top(pmets, value_col),\n",
    "            'rca':          top(pmets[pmets.rca > 1], 'rca'),\n",
    "            'market_share': top(pmets, 'market_share'),\n",
    "            'pci':          top(pmets[pmets[value_col] > thr], 'pci'),\n",
    "        }\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def _export_csv(self, top_opps):\n",
    "        out = self.config['output']['directory']\n",
    "        for strat, data in top_opps.items():\n",
    "            if data.empty:\n",
    "                continue\n",
    "            cols = ['product_name','sector_name','pci','distance','cog', strat]\n",
    "            fname = f'opportunities_{strat}.csv'\n",
    "            data[cols].to_csv(os.path.join(out, fname), index=False)\n",
    "            print(f\"  saved: {fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3bc191c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRADE ANALYSIS: Italy\n",
      "======================================================================\n",
      "Loading data from: /Users/leoss/Desktop/Portfolio/Website-/projects/export/data/atlas_2022.dta\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# RUN\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[1;32m      5\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m TradeAnalysisPipeline(CONFIG)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m, in \u001b[0;36mTradeAnalysisPipeline.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRADE ANALYSIS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m country_df, global_df, sector_mapping, sector_colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviz \u001b[38;5;241m=\u001b[39m Visualizer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, sector_colors)\n\u001b[1;32m     23\u001b[0m base_year    \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manalysis\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_year\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m, in \u001b[0;36mTradeDataLoader.load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[pd\u001b[38;5;241m.\u001b[39mDataFrame, pd\u001b[38;5;241m.\u001b[39mDataFrame, pd\u001b[38;5;241m.\u001b[39mDataFrame, Dict]:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# net exports\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_export\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexport_value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimport_value\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/stata.py:2109\u001b[0m, in \u001b[0;36mread_stata\u001b[0;34m(filepath_or_buffer, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator, compression, storage_options)\u001b[0m\n\u001b[1;32m   2106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader:\n\u001b[0;32m-> 2109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/stata.py:1757\u001b[0m, in \u001b[0;36mStataReader.read\u001b[0;34m(self, nrows, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals)\u001b[0m\n\u001b[1;32m   1755\u001b[0m     data \u001b[38;5;241m=\u001b[39m DataFrame(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_varlist)\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1758\u001b[0m     data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m Index(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_varlist)\n\u001b[1;32m   1760\u001b[0m \u001b[38;5;66;03m# If index is not specified, use actual row number rather than\u001b[39;00m\n\u001b[1;32m   1761\u001b[0m \u001b[38;5;66;03m# restarting at 0 for each chunk.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:2542\u001b[0m, in \u001b[0;36mDataFrame.from_records\u001b[0;34m(cls, data, index, exclude, columns, coerce_float, nrows)\u001b[0m\n\u001b[1;32m   2539\u001b[0m     columns \u001b[38;5;241m=\u001b[39m columns\u001b[38;5;241m.\u001b[39mdrop(exclude)\n\u001b[1;32m   2541\u001b[0m manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2542\u001b[0m mgr \u001b[38;5;241m=\u001b[39m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_mgr(mgr, axes\u001b[38;5;241m=\u001b[39mmgr\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/managers.py:2139\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[0;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[1;32m   2122\u001b[0m     arrays: \u001b[38;5;28mlist\u001b[39m[ArrayLike],\n\u001b[1;32m   2123\u001b[0m     axes: \u001b[38;5;28mlist\u001b[39m[Index],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2135\u001b[0m     \u001b[38;5;66;03m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[1;32m   2136\u001b[0m     \u001b[38;5;66;03m#  verify_integrity=False below.\u001b[39;00m\n\u001b[1;32m   2138\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2139\u001b[0m         blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_form_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2140\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   2141\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/managers.py:2212\u001b[0m, in \u001b[0;36m_form_blocks\u001b[0;34m(arrays, consolidate, refs)\u001b[0m\n\u001b[1;32m   2209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtype\u001b[38;5;241m.\u001b[39mtype, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[1;32m   2210\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m-> 2212\u001b[0m values, placement \u001b[38;5;241m=\u001b[39m \u001b[43m_stack_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtup_block\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dtlike:\n\u001b[1;32m   2214\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/managers.py:2254\u001b[0m, in \u001b[0;36m_stack_arrays\u001b[0;34m(tuples, dtype)\u001b[0m\n\u001b[1;32m   2252\u001b[0m stacked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   2253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[0;32m-> 2254\u001b[0m     stacked[i] \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   2256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stacked, placement\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RUN\n",
    "# ============================================================================\n",
    "\n",
    "pipeline = TradeAnalysisPipeline(CONFIG)\n",
    "pipeline.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e991fd6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Methods:** The pipeline loads Atlas of Economic Complexity data (HS-92, 4-digit product level) for Italy and all other countries. It computes product-level and sector-level metrics (export volume, net exports, RCA, global market share, PCI) for the base year (2022), and time-series trends (5-year rolling averages, 1995-2022). The opportunity analysis identifies products where Italy currently lacks comparative advantage (RCA < 1) but which exceed a minimum complexity threshold (PCI > 1.49), scoring them under three strategies with different distance/complexity/opportunity-gain weights.\n",
    "\n",
    "**Strategy formulas:**\n",
    "- Low-hanging fruit: 0.75 * proximity + 0.10 * normalized PCI + 0.15 * normalized COG\n",
    "- Balanced: 0.50 * proximity + 0.25 * normalized PCI + 0.25 * normalized COG\n",
    "- Strategic bets: 0.40 * proximity + 0.20 * normalized PCI + 0.40 * normalized COG\n",
    "\n",
    "**Outputs:** 20+ PNG charts (product bars, sector bars, time trends, opportunity scatters), 3 opportunity CSVs, 1 interactive treemap (HTML). All saved to the configured output directory.\n",
    "\n",
    "**Key fixes in this version:**\n",
    "1. Strategy weights aligned to report formulas (pci/cog were swapped in LHF; balanced and long jumps had entirely different weights)\n",
    "2. Product names resolved via external CSV lookup (1,241 products) instead of 30-entry manual dict\n",
    "3. Distance reversal uses standard `1 - norm` formula instead of non-standard negative offset\n",
    "4. PCI weighting in time series uses `export_value` (always positive) to avoid zero-weight edge cases with net exports\n",
    "5. Sector mapping filtered to base year to prevent merge duplicates\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
